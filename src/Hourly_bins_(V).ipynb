{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "RNXe3HGv9P8Q"
      },
      "outputs": [],
      "source": [
        "#@title Dataset Definition\n",
        "\n",
        "\"\"\"Smart Buildings Dataset implementation, including loading and downloading.\"\"\"\n",
        "\n",
        "\n",
        "import json\n",
        "import pickle\n",
        "import shutil\n",
        "import numpy as np\n",
        "import requests\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class SmartBuildingsDataset:\n",
        " \"\"\"Smart Buildings Dataset implementation, including loading and downloading.\"\"\"\n",
        "\n",
        "\n",
        " def __init__(self, download=True):\n",
        "   self.partitions = {\n",
        "       \"sb1\": [\n",
        "           \"2022_a\",\n",
        "           \"2022_b\",\n",
        "           \"2023_a\",\n",
        "           \"2023_b\",\n",
        "           \"2024_a\",\n",
        "       ],\n",
        "   }\n",
        "   if download:\n",
        "     self.download()\n",
        "\n",
        "\n",
        " def download(self):\n",
        "   \"\"\"Downloads the Smart Buildings Dataset from Google Cloud Storage.\"\"\"\n",
        "   print(\"Downloading data...\")\n",
        "\n",
        "\n",
        "   def download_file(url):\n",
        "     local_filename = url.split(\"/\")[-1]\n",
        "     with requests.get(url, stream=True) as r:\n",
        "       r.raise_for_status()\n",
        "       with open(local_filename, \"wb\") as f:\n",
        "         for chunk in r.iter_content(chunk_size=8192):\n",
        "           f.write(chunk)\n",
        "     return local_filename\n",
        "\n",
        "\n",
        "   url = \"https://storage.googleapis.com/gresearch/smart_buildings_dataset/tabular_data/sb1.zip\"\n",
        "   download_file(url)\n",
        "   shutil.unpack_archive(\"sb1.zip\", \"sb1/\")\n",
        "\n",
        "\n",
        " def get_floorplan(self, building):\n",
        "   \"\"\"Gets the floorplan and device layout map for a specific building.\n",
        "\n",
        "\n",
        "   Args:\n",
        "     building: The name of the building.\n",
        "\n",
        "\n",
        "   Returns:\n",
        "     A tuple containing the floorplan and device layout map.\n",
        "   \"\"\"\n",
        "   if building not in self.partitions.keys():\n",
        "     raise ValueError(\"invalid building\")\n",
        "   floorplan = np.load(f\"./{building}/tabular/floorplan.npy\")\n",
        "\n",
        "   def gdrive_to_direct_url(share_url):\n",
        "        file_id = share_url.split('/d/')[1].split('/')[0]\n",
        "        return f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
        "   share_url = \"https://drive.google.com/file/d/19W4exC1IfIpx6x_agZy3HO1ARXdxKnic/view?usp=sharing\"\n",
        "   direct_url = gdrive_to_direct_url(share_url)\n",
        "   response = requests.get(direct_url)\n",
        "   device_layout_map = response.json()\n",
        "\n",
        "   return floorplan, device_layout_map\n",
        "\n",
        "\n",
        " def get_building_data(self, building, partition):\n",
        "   \"\"\"Gets the data for a specific building and partition.\n",
        "\n",
        "\n",
        "   Args:\n",
        "     building: The name of the building.\n",
        "     partition: The name of the partition.\n",
        "\n",
        "\n",
        "   Returns:\n",
        "     A tuple containing the data and metadata.\n",
        "   \"\"\"\n",
        "   if building not in self.partitions.keys():\n",
        "     raise ValueError(\"invalid building\")\n",
        "   if partition not in self.partitions[building]:\n",
        "     raise ValueError(\"invalid partition\")\n",
        "   path = f\"./{building}/tabular/{building}/{partition}/\"\n",
        "\n",
        "\n",
        "   data = np.load(path + \"data.npy.npz\")\n",
        "   metadata = pickle.load(open(path + \"metadata.pickle\", \"rb\"))\n",
        "\n",
        "\n",
        "   if \"device_infos\" not in metadata.keys():\n",
        "     metadata[\"device_infos\"] = pickle.load(\n",
        "         open(f\"./{building}/tabular/device_info_dicts.pickle\", \"rb\")\n",
        "     )\n",
        "   if \"zone_infos\" not in metadata.keys():\n",
        "     metadata[\"zone_infos\"] = pickle.load(\n",
        "         open(f\"./{building}/tabular/zone_info_dicts.pickle\", \"rb\")\n",
        "     )\n",
        "   return data, metadata\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rm92LZNV98Cw",
        "outputId": "021d58fb-079c-490b-8092-a6c4adfed3c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data...\n"
          ]
        }
      ],
      "source": [
        "#@title Data download and splitting\n",
        "\n",
        "ds = SmartBuildingsDataset()\n",
        "\n",
        "# training data: Jan-June 2022\n",
        "data, metadata = ds.get_building_data(\"sb1\",\"2022_a\")\n",
        "floorplan, device_layout_map = ds.get_floorplan(\"sb1\")\n",
        "\n",
        "# validation data: July-December 2022\n",
        "data_val, metadata_val = ds.get_building_data(\"sb1\",\"2022_b\")\n",
        "floorplan_val, device_layout_map_val = ds.get_floorplan(\"sb1\")\n",
        "\n",
        "# lets split validation data into things to predict, and exogenous variables\n",
        "indexes = [v for k, v in metadata_val['observation_ids'].items() if \"zone_air_temperature_sensor\" in k]\n",
        "temp_data = data_val['observation_value_matrix'][:, indexes]\n",
        "matching_items = [(k, v) for k, v in metadata_val['observation_ids'].items() if \"zone_air_temperature_sensor\" in k]\n",
        "temp_data_ids = {k: i for i, (k, v) in enumerate(matching_items)}\n",
        "\n",
        "indexes = [v for k, v in metadata_val['observation_ids'].items() if \"zone_air_temperature_sensor\" not in k]\n",
        "exogenous_observation_data = data_val['observation_value_matrix'][:, indexes]\n",
        "matching_items = [(k, v) for k, v in metadata_val['observation_ids'].items() if \"zone_air_temperature_sensor\" not in k]\n",
        "exogenous_observation_data_ids = {k: i for i, (k, v) in enumerate(matching_items)}\n",
        "\n",
        "initial_condition = temp_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_qSwXSUb4ox",
        "outputId": "c81910d5-e608-49c4-cf78-75278a8c3001"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'2760348383893915@zone_air_temperature_sensor': 0,\n",
              " '2562701969438717@zone_air_temperature_sensor': 1,\n",
              " '2806035809406684@zone_air_temperature_sensor': 2,\n",
              " '2790439929052995@zone_air_temperature_sensor': 3,\n",
              " '2628534928204590@zone_air_temperature_sensor': 4,\n",
              " '2535333053617205@zone_air_temperature_sensor': 5,\n",
              " '2619255661594253@zone_air_temperature_sensor': 6,\n",
              " '2618781414146613@zone_air_temperature_sensor': 7,\n",
              " '2613654138967436@zone_air_temperature_sensor': 8,\n",
              " '2762982574975969@zone_air_temperature_sensor': 9,\n",
              " '2578499186529204@zone_air_temperature_sensor': 10,\n",
              " '2693289483686059@zone_air_temperature_sensor': 11,\n",
              " '2549483694528743@zone_air_temperature_sensor': 12,\n",
              " '2614466029028994@zone_air_temperature_sensor': 13,\n",
              " '2760979770441910@zone_air_temperature_sensor': 14,\n",
              " '2732460999450017@zone_air_temperature_sensor': 15,\n",
              " '2549513081490212@zone_air_temperature_sensor': 16,\n",
              " '2737293899563066@zone_air_temperature_sensor': 17,\n",
              " '2710040674126014@zone_air_temperature_sensor': 18,\n",
              " '2570355700484963@zone_air_temperature_sensor': 19,\n",
              " '2779591174908667@zone_air_temperature_sensor': 20,\n",
              " '2768768486087571@zone_air_temperature_sensor': 21,\n",
              " '2810271246509820@zone_air_temperature_sensor': 22,\n",
              " '2705858092749449@zone_air_temperature_sensor': 23,\n",
              " '2693840961422865@zone_air_temperature_sensor': 24,\n",
              " '2740082748651605@zone_air_temperature_sensor': 25,\n",
              " '2802781341872564@zone_air_temperature_sensor': 26,\n",
              " '2568004980110825@zone_air_temperature_sensor': 27,\n",
              " '2791846410789505@zone_air_temperature_sensor': 28,\n",
              " '2651420801112308@zone_air_temperature_sensor': 29,\n",
              " '2792140000757803@zone_air_temperature_sensor': 30,\n",
              " '2788179547754974@zone_air_temperature_sensor': 31,\n",
              " '2747395873491002@zone_air_temperature_sensor': 32,\n",
              " '2618581107144046@zone_air_temperature_sensor': 33,\n",
              " '2656676039327836@zone_air_temperature_sensor': 34,\n",
              " '2794597849078830@zone_air_temperature_sensor': 35,\n",
              " '2601599180090084@zone_air_temperature_sensor': 36,\n",
              " '2546477821573302@zone_air_temperature_sensor': 37,\n",
              " '2743847121700440@zone_air_temperature_sensor': 38,\n",
              " '2803088381116360@zone_air_temperature_sensor': 39,\n",
              " '2731964581915812@zone_air_temperature_sensor': 40,\n",
              " '2684239960710884@zone_air_temperature_sensor': 41,\n",
              " '2786928005384747@zone_air_temperature_sensor': 42,\n",
              " '2584468317047883@zone_air_temperature_sensor': 43,\n",
              " '2687242320524339@zone_air_temperature_sensor': 44,\n",
              " '2612620611294283@zone_air_temperature_sensor': 45,\n",
              " '2580539066022773@zone_air_temperature_sensor': 46,\n",
              " '2691496710334693@zone_air_temperature_sensor': 47,\n",
              " '2764530915698643@zone_air_temperature_sensor': 48,\n",
              " '2658280459967125@zone_air_temperature_sensor': 49,\n",
              " '2641439892024140@zone_air_temperature_sensor': 50,\n",
              " '2795032460499273@zone_air_temperature_sensor': 51,\n",
              " '2696593986887004@zone_air_temperature_sensor': 52,\n",
              " '2728593088050266@zone_air_temperature_sensor': 53,\n",
              " '2545072728476481@zone_air_temperature_sensor': 54,\n",
              " '2588159730413024@zone_air_temperature_sensor': 55,\n",
              " '2619215732412810@zone_air_temperature_sensor': 56,\n",
              " '2812366126877759@zone_air_temperature_sensor': 57,\n",
              " '2752553640836480@zone_air_temperature_sensor': 58,\n",
              " '2578850932476951@zone_air_temperature_sensor': 59,\n",
              " '2613479607618585@zone_air_temperature_sensor': 60,\n",
              " '2725518459642243@zone_air_temperature_sensor': 61,\n",
              " '2782657836669444@zone_air_temperature_sensor': 62,\n",
              " '2739555701122103@zone_air_temperature_sensor': 63,\n",
              " '2786127182232356@zone_air_temperature_sensor': 64,\n",
              " '2607380776570984@zone_air_temperature_sensor': 65,\n",
              " '2811944693103115@zone_air_temperature_sensor': 66,\n",
              " '2627283060405570@zone_air_temperature_sensor': 67,\n",
              " '2558614727946404@zone_air_temperature_sensor': 68,\n",
              " '2680684754684585@zone_air_temperature_sensor': 69,\n",
              " '2607531467124107@zone_air_temperature_sensor': 70,\n",
              " '2656411871653032@zone_air_temperature_sensor': 71,\n",
              " '2603432823050217@zone_air_temperature_sensor': 72,\n",
              " '2684906181773151@zone_air_temperature_sensor': 73,\n",
              " '2590610591373965@zone_air_temperature_sensor': 74,\n",
              " '2776979270669786@zone_air_temperature_sensor': 75,\n",
              " '2622037806906769@zone_air_temperature_sensor': 76,\n",
              " '2560929853112707@zone_air_temperature_sensor': 77,\n",
              " '2703938812282949@zone_air_temperature_sensor': 78,\n",
              " '2580869304551907@zone_air_temperature_sensor': 79,\n",
              " '2599277484308959@zone_air_temperature_sensor': 80,\n",
              " '2792898514969792@zone_air_temperature_sensor': 81,\n",
              " '2726572904605154@zone_air_temperature_sensor': 82,\n",
              " '2605375500053318@zone_air_temperature_sensor': 83,\n",
              " '2734562572216344@zone_air_temperature_sensor': 84,\n",
              " '2715399727027143@zone_air_temperature_sensor': 85,\n",
              " '2746959064186014@zone_air_temperature_sensor': 86,\n",
              " '2698594043420456@zone_air_temperature_sensor': 87,\n",
              " '2779757898406144@zone_air_temperature_sensor': 88,\n",
              " '2667818838237334@zone_air_temperature_sensor': 89,\n",
              " '2577372819803107@zone_air_temperature_sensor': 90,\n",
              " '2657554847589841@zone_air_temperature_sensor': 91,\n",
              " '2736579912341782@zone_air_temperature_sensor': 92,\n",
              " '2703995402831823@zone_air_temperature_sensor': 93,\n",
              " '2758068039436455@zone_air_temperature_sensor': 94,\n",
              " '2712344453081531@zone_air_temperature_sensor': 95,\n",
              " '2555387941965464@zone_air_temperature_sensor': 96,\n",
              " '2683563351071572@zone_air_temperature_sensor': 97,\n",
              " '2706839052470546@zone_air_temperature_sensor': 98,\n",
              " '2749879183751781@zone_air_temperature_sensor': 99,\n",
              " '2620112368775269@zone_air_temperature_sensor': 100,\n",
              " '2807442344300820@zone_air_temperature_sensor': 101,\n",
              " '2806531358805482@zone_air_temperature_sensor': 102,\n",
              " '2674020841435318@zone_air_temperature_sensor': 103,\n",
              " '2590087554896009@zone_air_temperature_sensor': 104,\n",
              " '2618254258255786@zone_air_temperature_sensor': 105,\n",
              " '2787448836354673@zone_air_temperature_sensor': 106,\n",
              " '2717096440251637@zone_air_temperature_sensor': 107,\n",
              " '16286830034440683520@zone_air_temperature_sensor': 108,\n",
              " '2578744141471091@zone_air_temperature_sensor': 109,\n",
              " '2657144210326005@zone_air_temperature_sensor': 110,\n",
              " '2720359073646091@zone_air_temperature_sensor': 111,\n",
              " '2766271641619615@zone_air_temperature_sensor': 112,\n",
              " '2696383178287941@zone_air_temperature_sensor': 113,\n",
              " '2591831048896702@zone_air_temperature_sensor': 114,\n",
              " '2538526995118004@zone_air_temperature_sensor': 115,\n",
              " '2651594506537727@zone_air_temperature_sensor': 116,\n",
              " '2696614388023593@zone_air_temperature_sensor': 117,\n",
              " '2720149542779272@zone_air_temperature_sensor': 118,\n",
              " '2805009894538456@zone_air_temperature_sensor': 119,\n",
              " '2559962019321287@zone_air_temperature_sensor': 120,\n",
              " '2606839440408366@zone_air_temperature_sensor': 121,\n",
              " '2640423556868160@zone_air_temperature_sensor': 122}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train data:\n",
        "data['observation_value_matrix']\n",
        "metadata[\"observation_ids\"]\n",
        "metadata[\"observation_timestamps\"]\n",
        "\n",
        "data['action_value_matrix']\n",
        "metadata[\"action_ids\"]\n",
        "\n",
        "floorplan\n",
        "device_layout_map\n",
        "metadata[\"device_infos\"]\n",
        "\n",
        "# Validation data:\n",
        "data_val['action_value_matrix']\n",
        "metadata_val[\"action_ids\"]\n",
        "metadata_val[\"observation_timestamps\"]\n",
        "floorplan\n",
        "device_layout_map\n",
        "\n",
        "exogenous_observation_data\n",
        "exogenous_observation_data_ids\n",
        "initial_condition\n",
        "\n",
        "# Predict:\n",
        "temp_data\n",
        "temp_data_ids\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "2NmpFoxupB_4",
        "outputId": "7bbca74a-8be7-49f3-e7d9-b8cb6b715665"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGgCAYAAABWo0bIAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAOhpJREFUeJzt3QuQVNWdx/H/DI/hOSAojERAAkZAURANjBqTwARE4qpQrqYQ0VBaEiACWSRkEQWEcdlsMLo8khQLpgKLoUpIRILAoLiR4emaCBgEH4FVHhsRBszy7q1zUt3pbrpn+nbf1zn3+6lqhn7f57m/Pvecc4tisVhMAAAALFEc9AQAAAC4iXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKwSaLiZO3euXHnlldKoUSPp06ePbN26NcjJAQAAFggs3Lz00ksyYcIEeeqpp+Ttt9+W66+/XgYOHChHjhwJapIAAIAFioK6cKaqqbnpppvk3//93/X9CxcuSPv27WXs2LHywx/+MIhJAgAAFqgfxJeeOXNGduzYIZMnT048VlxcLBUVFVJdXX3R60+fPq1vcSoIHT16VFq3bi1FRUW+TTcAAMifqk85ceKEtGvXTh/3rQo3f/nLX+T8+fPStm3blMfV/T/96U8Xvb6yslKmTZvm4xQCAACvHDhwQK644gq7wo1TqoZHtc+JO378uHTo0EH+/PaVUtqMDl8AAJig5uQF6XjDx9K8eXNPvyeQcHPppZdKvXr15PDhwymPq/tlZWUXvb6kpETf0qlgU9qccAMAgEmKPG5SEkgyaNiwofTu3VuqqqpS2tGo++Xl5UFMEgAAsERgp6XUaaYRI0bIjTfeKF/96lflueeeky+++EIefvjhoCYJAABYILBwc99998n//u//ytSpU+XQoUPSs2dPWbNmzUWNjAEAAIwY56YQNTU10qJFC/n8/S/T5gYAAEPUnLggl3zlQ90xqLS01LPvIRkAAACrGNEVHHXr/NJjtT7/wX0LfJuWqC7jdCxzmLjtst26g/IiWISbiOw46vXsPADqQlnhf/kM9xFuLNtpuozfnHJ/35y+Ke+l0Cpc+jJOF1/mLG+ErcyobdtNLivgHsqLYNDmxvBgo3ac5Fum5+v6DABILisoJ/wJNvAO4cZQ2cJMttcmo+Byzskyo0BDGDndLtU2T1nhnNNlRnnhDcKNgfLZGQg4+WNZwVQcaP0RD4KUFeHBODd5CnIjLqQASj+vzjleZ+s512Uf5vYLrHNvhfUA57TcSN6G2Wacr28ny9tpeRFfH25uax/4tI79GueGBsURo3Y4Ghl7G2wQXbYEm7rmizIjM7/KiLBuZ2FCuCmQ3wc8N2oECDj+B5t835++vt2stYN5ZYNah36VOenlRDLKjIsVsl4KrRFOX1ddPKw1MgXhJqIIONlRY4NC2bLNMLSEOU0SbNnm3EKD4gijkfHFCDZAdlEvM6I2vyaj5ibiqMGJXrCxtYDOZbst9DIEti47J6JaZtRWPth6asdkhBtEtrCqja3BxmZuBw8a0WYXtTIjKj98bEK4QdbCSrG5wMrG1oIr7POVb2PZfH4153MZglwvYxAVUQk4BBszEW6QU+8I23G6wVxuH2xqa0SLaAUcgo25aFCMvC/rAEQR+0c0GhkTbMxGzQ0ip7bClwIM2Won2Daic1qbYGM+am4QKbb8qoQ/1AGb01K5sSUAEGzsQM0NHIcBm36NceBCXTi4OV9W8f3KtBocgo09CDe4SF0HfBMbDWYrtBirAkCmH3EEG7MRbpBRph3bxF4RFFqA/0yqwaGMsBNtbhCpXhEUWn9vR0JNFfwWtjIjU40uZYQdqLmBteNa5Dvomu0H/fRf1YCf21pYygza19iNcAOrA45T8fkqtKDzKjgkfy6FMUwRtjKDYGM/TkvBylNU+dTaZGpkHDbJ1ebUvMAkYdmvCDbRQLiBVQFHTUMYpiOd20GEAhkmCnq7JdhEB6elYE11c9h7Pbh1yivf70V+4qMT17YcvaxNC9M2bDJTgw37b34IN7Bi6PWwFlxqGcSnLb6c3BzKP9eCLyzLwzTJ6yx+v6514OaytvnAlrzPel1WhLV8yJWX07vP0m2McANXZPpl61ctTpgLLi9HRQ7TfNrMlOXsZcjymp81viYtF+SPcANju32G/TRUvmz9JWUzL9eZk882obF5+j6aPNCf1wHHhvIBuSHcwJp2OG6f6nGzIMxWoOf6eoSXl+sq03aTqYYm0/ZkypXMk6c/zCMZwyyEGxgZcPIdoC8Mv3xNOOAgnGoLO8nPcVHYvwtj70l4j3ATcV6ep/eigKWgAnLfX4PqoReWa1FRXkQX4QZZayvcGA3XzYAT9jY2meYzTNOH6O7XUTsNGvayAt4j3CCQcOL0F1kYe0QRZmCCXGp3wtI+p5DTwrXV0oRh3uAvwo2hvL52UW21OG4UGk7a4PgVbHKdZz+mBQhqLJ/4Y2FQaFu9sMwH/Ee4MURywePVefRsn5ft8XwGkHPayNirhsPZUBgiirLtoyYGHPZh5HVtqTfffFPuvPNOadeunRQVFcnKlStTno/FYjJ16lS5/PLLpXHjxlJRUSF79+5Nec3Ro0dl2LBhUlpaKi1btpSRI0fKyZMnWSM5XjQx+eKJpkmf9mzXgkp/3NT5BeB9OUHDYRQcbr744gu5/vrrZe7cuRmfnz17tjz//POyYMEC2bJlizRt2lQGDhwop06dSrxGBZtdu3bJunXrZNWqVTowPfroo04nBZZddDNbQUWwAaLJ6Q85ygrkfVpq0KBB+paJqrV57rnnZMqUKXLXXXfpx375y19K27ZtdQ3P/fffL++9956sWbNGtm3bJjfeeKN+zQsvvCB33HGH/PjHP9Y1QsgsLI3+/GysbNP8AvAG5QQ8bXPz0UcfyaFDh/SpqLgWLVpInz59pLq6Wocb9VediooHG0W9vri4WNf03HPPPRd97unTp/UtrqamRqLGi4suhvFcv03zBqTLpz0L+wQQcLhRwUZRNTXJ1P34c+pvmzZtUieifn1p1apV4jXpKisrZdq0aRJ1jDoKmCufjgDZei+mIwABBvaWmjx5skyYMCGl5qZ9+/aBThNgoqDCcVAH37DMrxs9HGt7r8lXBM9nHdKAGL6Gm7KyMv338OHDurdUnLrfs2fPxGuOHDmS8r5z587pHlTx96crKSnRNwCF8/vAF3RtY9Dz68clENJP7/oxZk0h6zXXacr1O0y5zAQMDTedOnXSAaWqqioRZlQti2pLM2rUKH2/vLxcjh07Jjt27JDevXvrxzZs2CAXLlzQbXMAW7h5UKfQNk9Qg+K5MWZNrlcez2e+nE5TpquGZ/p+G9skwsdwo8aj2bdvX0oj4nfeeUe3menQoYOMGzdOnnnmGbnqqqt02HnyySd1D6i7775bv75bt25y++23yyOPPKK7i589e1bGjBmjGxvTU8o8/GKqnRvLJeiaD+TPxP0i1yuPh227pk0iCgo327dvl29+85uJ+/G2MCNGjJDFixfLE088ocfCUePWqBqaW2+9VXf9btSoUeI9S5Ys0YGmf//+upfU0KFD9dg4MPvCfCYW5E65fRkKJ98bheWLcPJq28v1c9n24Xm4+cY3vqHHs8lGjVo8ffp0fctG1fIsXbrU6VcjpGz/xVRXY02v5z392j8mFvSEM/OYvk/7Pf2mLy/bGNFbCnYLW6GQT9sCrw/ehVwtOYwXZow/7jYTl08Y58n0IB1n4vRHYZv2A+EGgQhr19V8CnVbB1h0kx+1XSYfkOvatoKYJ1OXo6nTDXcRbiBRDzRuHEiy1U54wZYQ5eZ82BhsAOSPcFOgQro11vaaQr8nCLlMo80HHz9qJ2xp3+RmbRfBBkA6wk2B8hlKvbb31Vbgh7nwDvO02ciG2ptCa7tsa1sBwD2EGwMKfApu2Fh748aAc+wbiLNln4A7CDchVNtQ6gBgOq/KNMIu4gg3IRfFgfIA2IsyDH4o9uVbEOlxTgDAD9R0I45wYxB+8QBA9vKRMhJxhBsAAGAVwg0AALAK4QYAAFiF3lIIFTcaA+Y7sKKb05Dts2qbNqffS8NJAMiMcIPQKaRRoJMu8/kO259vl/xsV8bOd8DGfKaDQAQgCgg3BWLsmfDV2jgJOH6uu0zXnuK6SPADoRZRQ7hxAZdKcI8byy+XgBOGwp5tBX4q9HQtYBIaFOfpg/sWJP7P+ArhE7ZaGwCAf6i5gaty/cXnV7DIVHvDr1IAsBvhJk+dX3os6EkInVzbj/gVLmq7eja1NoD9+CETXYQbl8NMFBsY59PmyM/lFP8uCjogekwvj/0qtzonHeOSm12YKhLhxstaluQdJ7khazbx52w70DopQJz2aCp0umjwbTc39yW2D8Cd42fQASkS4cZNdRV+FI7hCziwl5td6W37wRF2LO9w6JK079i0TiIVbvIdeA3e4FQRCkUwNpsX648yxRtOmhyEQaTCDQDzhaXwBGzV2YIOM4QbAHnxoi1TXacpGdE5d7a27wNyQbhB4Ch8zeVm26m6PotgkzuWFfIR315saAtJuEGgbG3MFiVutp1K73GYXNgm37eVk6vI18X2ZQXUhnADRIxX4/64dWBODzRRCTbZ5h+Ac4SbiHNSgEbl4GKzbDUjbnxuMre+I2rBBrCpUfIHAY51Q7hBTgcOxqSxhx/rMLn2IZ/tJqhQ41ZtiVuNeYNsFGxyzZHJ0w53EG6QE8akgV8NjoMKNmEL7k6mx+0fHmFbFrlgJPJw6BKSY0Vx0BMAs4Rho4W9bUg4DYVCqO2GbQcKNTeW8fIq2GFJ5LCzBodgA8At1NxYJPngkHwDwl6DQ7AB4CbCjQW86P1S1/cBbgccgg1gl84BXsaBcGNRqMll2Hq3e8EATjGOCwCvEW4MlWuoib8m/h43Diic7kKhCDiAvbqE4PhAuInIBkQgQdgQcACEItxUVlbKTTfdJM2bN5c2bdrI3XffLXv27El5zalTp2T06NHSunVradasmQwdOlQOHz6c8pr9+/fL4MGDpUmTJvpzJk6cKOfOnXNnjgBLxWvebDolSMN3uMmmfQM+dgXfuHGjDi4q4Kgw8qMf/UgGDBggu3fvlqZNm+rXjB8/Xl599VVZvny5tGjRQsaMGSNDhgyRt956Sz9//vx5HWzKyspk06ZNcvDgQXnwwQelQYMGMmvWrAJnB/DmchPp7wuqAOVCo4A3o2IjwuFmzZo1KfcXL16sa1527Nght912mxw/flwWLlwoS5culX79+unXLFq0SLp16yabN2+Wvn37ytq1a3UYWr9+vbRt21Z69uwpM2bMkEmTJsnTTz8tDRs2dHcOcZEod7t1OkpuPu8FEJ7rp3n5PYqb35NtLDF+yPg8iJ8KM0qrVq30XxVyzp49KxUVFYnXdO3aVTp06CDV1dU63Ki/PXr00MEmbuDAgTJq1CjZtWuX9OrV66LvOX36tL7F1dTUiI38OKDSziF3UQ6BgMm83mfTw5Mb3+f3kB61seH4kHe4uXDhgowbN05uueUWufbaa/Vjhw4d0jUvLVu2THmtCjLqufhrkoNN/Pn4c9na+kybNk1slmmjpno1OHR5B+Dn6WHK+ZD0llJtb3bu3CnLli0Tr02ePFnXEsVvBw4cEFvUltY5wAYvubEr6wEALK65UY2EV61aJW+++aZcccUVicdVI+EzZ87IsWPHUmpvVG8p9Vz8NVu3bk35vHhvqvhr0pWUlOibLQk9/XNqS+yZDqwkfP9xOg8ALK25icViOtisWLFCNmzYIJ06dUp5vnfv3rrXU1VVVeIx1VVcdf0uLy/X99Xfd999V44cOZJ4zbp166S0tFS6d+8uUeG0CyzdZQEA8KDmRp2KUj2hfvOb3+ixbuJtZFSX78aNG+u/I0eOlAkTJuhGxiqwjB07Vgca1ZhYUV3HVYgZPny4zJ49W3/GlClT9GcHVTsDAAAiGm7mz5+v/37jG99IeVx1937ooYf0/+fMmSPFxcV68D7Vw0n1hJo3b17itfXq1dOntFTvKBV61Pg4I0aMkOnTp7szR0DE+HGqjFpDe9hwapXtEa6GG3Vaqi6NGjWSuXPn6ls2HTt2lNWrVzv5agABor2XN6EhqOVp8nq0IZwh5OPcAAiPD+5b4Ppndn7pMYkSDpyAHQg3AOoMTFELOV6HTC+Wp5NemIDtCDcA4EMtmJfiw/YzZAHwN4QboEBODyQm/6KubV5Nmi8O/uZzYx2atM1GsbwpBOEm5DtfbRdRK/Tz3fgct6Yl/fOyyfeXqZvTWcg1wLikBrwQtYstutHA3eTlU8gFgKPC+nATdFsBNw5iYT4Q+nmgTg8GYV4uTq/6a/JpmqD3sSidfqpN8v5g4r7hhO3z56Z9Ll/g0/prS5nA5EIXF7OpPQHXqQIQtpHwbWJ1uEkWxZVrIxt2VBvmAQDCLBLhhgMJAADRYX2bGyDM3GoUDgCIWM0NAACIDmpuAEN77NBgPlqopQNyR7gBDGVTN+aoynW8FoIN4AzhBgAC5iS8pIdaavCAixFuAMCQC5JSW+cuv0ZWdws9f3NHuAHgawFfaAFt0ykawkpwTAsKNm33fiDcAPBVrtcPA4B8EW4A+FL74HbbEGo9AGRDuAHgi7rCSC7hh6p5oDD70vYhW2tKCTcAQoUAA3iri0UXIc4mUuEmnxVpa6oFTMYpKURdPsezfRnek8vnmBiCIhVunIYVtULVjYADeI/AArg7+GNdsr0//vnJocbpdwUdiLi2VC0INQCAMB6X/Do+dRm/2chjYeRqbvIRdAIFAMDPY9E+w497hJs6JCdW01c2AMBcftbW7DO8SQanpQAAgFUiU3NDrQvcwHYEm7fN+C92wHSRCTeKyVVsAOAXykqYLlLhxg1Of9XwK8hOdFuGTdui25fGAIJGuAn5LxrCEQAAzkSiQTEBAQCA6CiOSnVtvjUuhYzQCACAiboY3rjc6nADAACih3ADAACsQrgBAABWobeUYVeA9fMcaK7f58U05XLZC5PPBwNAWOyrpSxNf86UtqeRCTeFHAizvdePlRz/DjUNbl3mPq62a4d48X1OpiusOxSBCkCU7TOkDIxMuDGd3wf3IMNEWIIMANgcADL1ME4f0DHe69i0gR4dhZv58+fr28cff6zvX3PNNTJ16lQZNGiQvn/q1Cn5wQ9+IMuWLZPTp0/LwIEDZd68edK2bdvEZ+zfv19GjRolr7/+ujRr1kxGjBghlZWVUr9+fWNGkjVtJQMA/GXqj7QPshwzTRuV3VGD4iuuuEKeffZZ2bFjh2zfvl369esnd911l+zatUs/P378eHnllVdk+fLlsnHjRvn0009lyJAhifefP39eBg8eLGfOnJFNmzbJiy++KIsXL9YBCQAAwA2OqkvuvPPOlPszZ87UNTmbN2/WwWfhwoWydOlSHXqURYsWSbdu3fTzffv2lbVr18ru3btl/fr1ujanZ8+eMmPGDJk0aZI8/fTT0rBhQ1dmCgAARFfeXcFVLYw6/fTFF19IeXm5rs05e/asVFRUJF7TtWtX6dChg1RXV+v76m+PHj1STlOpU1c1NTWJ2p9M1Cku9ZrkGwAAQCaOG7q8++67Osyo9jWqzcyKFSuke/fu8s477+ial5YtW6a8XgWZQ4cO6f+rv8nBJv58/LlsVJucadOmOZ1UwOrGf4BX+0Ku+4Sp7UpgP8c1N1dffbUOMlu2bNENg1WDYHWqyUuTJ0+W48ePJ24HDhzw9PsAAECEam5U7UyXLl30/3v37i3btm2Tn/70p3LffffphsLHjh1Lqb05fPiwlJWV6f+rv1u3bk35PPV8/LlsSkpK9A3wkmm9AYCgtn16jML6yy9cuHBBt4lRQadBgwZSVVWVeG7Pnj2667c6jaWov+q01pEjRxKvWbdunZSWlupTWwAAAL7W3KjTQ2pMG9VI+MSJE7pn1BtvvCGvvfaatGjRQkaOHCkTJkyQVq1a6cAyduxYHWhUTyllwIABOsQMHz5cZs+erdvZTJkyRUaPHk3NDAAA8D/cqBqXBx98UA4ePKjDzHXXXaeDzbe+9S39/Jw5c6S4uFiGDh2aMohfXL169WTVqlW6rY4KPU2bNtVtdqZPny5RbYhKgzwAQD7oDOFSuFHj2NSmUaNGMnfuXH3LpmPHjrJ69WonXwsAAJAzri0VUMNTGuQBANxAZwgPGhQDAACECeEGAABYhXADAACsQpsbAECoe+7QqxROEW4AAKENIXR3Rj44LQUAKAgBBGFDuAEAFIxTRwgTwg0AALAKbW4iXp0b9PfXhV+DAMJeTtkyzTah5gYAAFiFmpuAMFx27bg8BYB0lJvIFTU3AADAKoQbhBrnrQEAThFuAACAVQg3CCXOrQMA8kW4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACr1A96AoC6cPFMIPz7Zl37aZfxmwv6fMAJwg0AwHMEFfipKBaLxcQwNTU10qJFC/n8/S9LaXPOrAFAWHV+6bGCP4ML6dqj5sQFueQrH8rx48eltLTUs++h5gYA4BmCCYJAtQcAALAK4QYAAFiFcAMAAKxCmxuPGsKp88yFvr/Q6Yh/hhvTEeRnZDpn7/Sz3FieyZ/j1rotlJvL1AZh2E6zvT+XMiHo/S3bdlHIZwVZftk0HcmfgboRbmCcfAoH9Z5CA6fbKOSiJUzbXl37CWA6uoLnUAg5GXwq01gOhbw/+YCc6+dkG0+i0Pnw+zNyGRejrs+q7TOS35v+uvTPzXVeavscL8f5cLpebD2AOd1XvNxO4+/PpUwIen/Lddss5LP8LL+CnA71vlz2+3zXren7bg1dwWHKr72g5FI4qNcUGji95sYBDOYI07ZX136C8KF2LTfU3Lj06y9ZciHhxmcU+ln5qqs2w6Zpcevzc/mcoJerrTU3yT8E8h3q34t14ff6DsP2Vej3Bz0PhfBjOzJ5/62h5sZcbmzYYfgllVytblLhguBrBAtpwB22tlGF8uvUJOwWhmOCSQqq9nj22WelqKhIxo0bl3js1KlTMnr0aGndurU0a9ZMhg4dKocPH0553/79+2Xw4MHSpEkTadOmjUycOFHOnTtXyKQACBEVTuK3fN5bCII4gLxrbrZt2yY/+9nP5Lrrrkt5fPz48fLqq6/K8uXL9amjMWPGyJAhQ+Stt97Sz58/f14Hm7KyMtm0aZMcPHhQHnzwQWnQoIHMmjWr8DmClahFco/TRthutQnKp/G3W41IYRZquxBIuDl58qQMGzZMfvGLX8gzzzyTeFydQ1u4cKEsXbpU+vXrpx9btGiRdOvWTTZv3ix9+/aVtWvXyu7du2X9+vXStm1b6dmzp8yYMUMmTZokTz/9tDRs2LDgmQIQTJAM6r0AUPBpKXXaSdW+VFRUpDy+Y8cOOXv2bMrjXbt2lQ4dOkh1dbW+r/726NFDB5u4gQMH6kbCu3btyvh9p0+f1s8n3wAAAFypuVm2bJm8/fbb+rRUukOHDumal5YtW6Y8roKMei7+muRgE38+/lwmlZWVMm3aNKeTCgAAIshRzc2BAwfk8ccflyVLlkijRo3EL5MnT9anvOI3NR0AAAAFhxt12unIkSNyww03SP369fVt48aN8vzzz+v/qxqYM2fOyLFjx1Lep3pLqQbEivqb3nsqfj/+mnQlJSW6P3zyDQAAoODTUv3795d333035bGHH35Yt6tRDYLbt2+vez1VVVXpLuDKnj17dNfv8vJyfV/9nTlzpg5Jqhu4sm7dOh1Yunfv7mRyAM942ag1Pl4FjWbhhaC3q/SeTmzrCH24ad68uVx77bUpjzVt2lSPaRN/fOTIkTJhwgRp1aqVDixjx47VgUb1lFIGDBigQ8zw4cNl9uzZup3NlClTdCNlVUMDBCHTtX4olIHCMPAcguL6tQvmzJkj3/72t3XNzW233aZPNb388suJ5+vVqyerVq3Sf1XoeeCBB/Q4N9OnT3d7UoC8EWoAwFwFX37hjTfeSLmvGhrPnTtX37Lp2LGjrF69utCvBgBEgGm1P25PLz+2nOPaUjCCaYUbEPS2bNMB0aR5cft0NmVffgg3MEJQhRsFS7T4cTVqP7bl+HwEuf0mt7fJdzpMCjVeohxyjnADuFiwUgiZK70Xmy3rMoiAkLzs8v1+W5Z/oWzbHo1tUAwAJuLggTCjFssZam4iXJAWOg1O3u9Wl1B2cH8Vss5MfG+mIQEQHJY/8kW4CXDHqutAnf79XkxPLmEhPuZL8nvi93N9v5Pvy+Vz4L2oB0kv5p9tOHecjkEhCDchLtyTd+4gpyXTiKPpjwMAEBa0uYEj8UBDsMlNPAzy6xNxbA+A96i5Qc4okJ2jah1R3R6iMI8IL2pukJPkU1HU2gCoTXI5QchBEKi5Qc4INYWhkEfUFNpLkn0G+SLcAD4gGMIvYRid2E3sO8gH4QYwZNh+2MXLXpBsf4g6wg3g0QBwQF2na7Jtb2xLQGEIN4g8al3CHyBtXCfZ5ilb6DFxGdh2iixXUZvfMCLcILLcGjk5LEwKaU6mLX6wD/P8uCnTfJo8eGYURyVndOvgEW4QKSYFgHzY2P3WreuS2bJeo74sgFwQbpCzXKrKw1jw2hpowrisvWRqzYWbojzvgBOEG+Qs1yATlsBj6mknp1dbjwIba6QAeIdwg4KE8WBjaqhJZup0A/AGp2edIdzAigOwiaeebOkRAwBhQ7gxRJCJPcwHXBNrabJNc1h/ldU2XaYs82y8WuamL5cwCuv+gXAi3BgiqMLS7QLFjTBiSi1NGEJBoesvPp3Zuie78R1BNCz2MhTbNE5NWJjUmJwQFg6EGxjVMNSkQi4s0+lWiPTiO4JsWOznpQ844NmxL8EchBsEpraB2TL9sg669iqXXmDJr6EwBtxpRMu+BKcINwjltXXirwlSXacugp4+mCWX2hu2KcAdhBsExoSC3IRphB01ENnCDxfXBJwj3MDqnkmwl5OG5aa3ecl0SpT9EciOcIOcMUoswiKfUbBNDAC51NpkOr0bpnmlzQyCQLiBpwVWUN2FET3pDb9N3+Zy7RkYlsud5Nq2zkkNG6EI+SLcwJPGwOmvD1uhC7uvmh10Dzu3mD79tdUyZZs3ygu4gXADKwrdfAvCsM0HCsP1d8wKocmPs97gJsINjFVoFTaFKcIoCtul09ocwCnCDYzjZi8RGjsijKK0TUZpXuGfYh+/C3C1QCy0UOTcvr1MXaemTrdXWB7IF+EGkS5g+NVob/A1bd3a0gjaLSauQ4QHp6WQUZTPgdsc5gBTsB+iEIQbBD7GRF2FmB/Tkd72JoqhDgiL5P2RBsfw/LTU008/LUVFRSm3rl27Jp4/deqUjB49Wlq3bi3NmjWToUOHyuHDh1M+Y//+/TJ48GBp0qSJtGnTRiZOnCjnzp3La+LhjuSxQfyu0k8utDLdkl/jFQpMINw/srJ1IQdcq7m55pprZP369X//gPp//4jx48fLq6++KsuXL5cWLVrImDFjZMiQIfLWW2/p58+fP6+DTVlZmWzatEkOHjwoDz74oDRo0EBmzZolpsm0k5l0oAzq2jROaoj8HP+CnlPOhfFA48U0ZdounA5iadMy8XqeMn2+bTU5ph8/rAs3KsyocJLu+PHjsnDhQlm6dKn069dPP7Zo0SLp1q2bbN68Wfr27Str166V3bt363DUtm1b6dmzp8yYMUMmTZqka4UaNmwoYeL0ejW5/KoIcuMNw9Dm+RZKXgcPBhHLrLZlEuaC2M1pK+Sq3OkjJgfJrWnwcj/Jp8zN9HjQ8gm+1EoFHG727t0r7dq1k0aNGkl5eblUVlZKhw4dZMeOHXL27FmpqKhIvFadslLPVVdX63Cj/vbo0UMHm7iBAwfKqFGjZNeuXdKrV6+M33n69Gl9i6upqRE/ON1Z6np9UBtumAqAfL6f4BGMoLcVp7zeRvL5ceD0UiVeMGXfyScEhrE2J77O3T5+mLQujQs3ffr0kcWLF8vVV1+tTylNmzZNvva1r8nOnTvl0KFDuualZcuWKe9RQUY9p6i/ycEm/nz8uWxUgFLfBbNqaQC/BXG6xIv3uC0M0+DlQbu2yzogmhyFm0GDBiX+f9111+mw07FjR/n1r38tjRs3Fq9MnjxZJkyYkFJz0759e8++z2Ts2ID7TP3F7Od0F3p9NzfKq9pO81AeRktBXcFVLc1XvvIV2bdvn3zrW9+SM2fOyLFjx1Jqb1RvqXgbHfV369atKZ8R702VqR1PXElJib4hs6B3YL8axpl6gIHZTB/J2s8yIZ+2dF61SeL6VdFWULg5efKkfPDBBzJ8+HDp3bu37vVUVVWlu4Are/bs0V2/VdscRf2dOXOmHDlyRHcDV9atWyelpaXSvXt3N+YnUsLS2yn9+70osLI1IrSNzfNmA1MOkH5vR4XW2niNruTR4yjc/NM//ZPceeed+lTUp59+Kk899ZTUq1dPvvOd7+iu3yNHjtSnj1q1aqUDy9ixY3WgUY2JlQEDBugQo8LQ7NmzdTubKVOm6LFxolQzk8/OFYZug7mGKRoAR7OGwHZ+rR83Pj+IHzthD3xhGpgUIQs3//M//6ODzGeffSaXXXaZ3Hrrrbqbt/q/MmfOHCkuLtY1N6p3k+oJNW/evMT7VRBatWqV7h2lQk/Tpk1lxIgRMn36dIkaEwqCQguwsHSBBUyRb0+boA+s7OcwOtwsW7as1udV9/C5c+fqWzaq1mf16tXitc4vPeb5d0SNkwKM2pvgxZe/07FDgmDqtmLSQH5eMHW9mS6f49sH9y2QKOHaUvAUtTfBcFrDFuR6cuu0RlAHWjfHtzIlLHjd3i/Mg6GaHIg+iFDAqW97qnVayMM91N6YIXmguaAOGqYdrLzcrsO+LNw4dZbr92RCz6e/Y+C/iIWbfEWlR47fDZWjsixNXk51jaRL1/7CyglqMN2vtWEcm9x0ieiPTKvDDRt7dtkKBS8vsBfFHcykbba2X8pui9Iv76geXLzeLihbENlwg4vl8kuHX5nwUpSCDZxju4Abil35FIRe+nnqbAUIY63ASwSbujHQHFA4am5q4WV1fJgPKFSjw6RgY9O2GuUfF7bMs5MhGOAdwk3APQL8ks982DT/TnldMEVpufrR6DNKy9NGttXo0QA/eIQbhLZ7cJC8nGcTl2u+02vbQQveYPuA22hzg6wocLxh2kX88jlVwlgkAIJEzQ0QgoAT9gDgpCaPUOMdE8IwEAaEGyBAdQ2eF+ZpzRReCDbeyXXZmrAtAV4j3AABM6mHTLYaJ0aK9Ub6NsGyBXJDuAHgWPJwAdTWeIPlCuSPcAMgbxyA3ccyBQpHuAECYMvpBlOnO6wINoA76AoOBCT5MhgmtLeBPwg2QOGouQECxsEMANxFzQ2AvJnSjR1AtBBuAOSF02oAwopwA6AgBBwAYUObGwCujnsDBCUs22Cm6aBtnb8INwAAa+R79Xovw0dYQlfnlx6TD+5bIFFAuPFYWDbqQqYjfSTaoKbDi8/J9rlerjfbf8HZMoYPAHMRbnzgZuFuwhWkvWLDvIcl7Po1CJ3t8wuYoEsETxsTbgC4xvTwCZiyb0UtrDhFuAFQEApZAGFDuAGQN66FBCCMGOcGQF4INgDCipobIIKng2oLJE4+N0zBptDTY2GaFwCFsS7cqH78hRZ2FHKwXV37Rpj3gUzT7uYwBUHPe5iGXAj6O0yeHj9EcZ4jG27cGMwp+S8Qdk4H5Ur+AWCjQpeH033f7bIi6HDlJhuGbwgrp8t1X8SOadaGGzd2KHZKRO3gb1LwcWuk1fjnxOfdyX7PwRsIJxoUAwAAqxBuknBKCgAA81l7WipfVDEDAGA2am4AAIBVCDdpOCUFr7GNAUDIws0nn3wiDzzwgLRu3VoaN24sPXr0kO3btyeej8ViMnXqVLn88sv18xUVFbJ3796Uzzh69KgMGzZMSktLpWXLljJy5Eg5efKkBI0rGcOPbYxTnwAQonDz+eefyy233CINGjSQ3/3ud7J79275t3/7N7nkkksSr5k9e7Y8//zzsmDBAtmyZYs0bdpUBg4cKKdOnUq8RgWbXbt2ybp162TVqlXy5ptvyqOPPiphwIEHXiM827c+WaeAwQ2K/+Vf/kXat28vixYtSjzWqVOnlFqb5557TqZMmSJ33XWXfuyXv/yltG3bVlauXCn333+/vPfee7JmzRrZtm2b3Hjjjfo1L7zwgtxxxx3y4x//WNq1a+fe3AEhRYi2A7W9gAXh5re//a2uhbn33ntl48aN8qUvfUm+973vySOPPKKf/+ijj+TQoUP6VFRcixYtpE+fPlJdXa3DjfqrTkXFg42iXl9cXKxreu65556Lvvf06dP6FldTU5Pv/ALIgZsHaw78AEJ9WurDDz+U+fPny1VXXSWvvfaajBo1Sr7//e/Liy++qJ9XwUZRNTXJ1P34c+pvmzZtUp6vX7++tGrVKvGadJWVlTokxW+q9ggAAKDgmpsLFy7oGpdZs2bp+7169ZKdO3fq9jUjRowQr0yePFkmTJiQUnNDwAHCe0kDADCm5kb1gOrevXvKY926dZP9+/fr/5eVlem/hw8fTnmNuh9/Tv09cuRIyvPnzp3TPajir0lXUlKie1Yl3wAAAAquuVE9pfbs2ZPy2Pvvvy8dO3ZMNC5WAaWqqkp69uyZqGVRbWnUKSylvLxcjh07Jjt27JDevXvrxzZs2KBrhVTbHCAqaIsSTqwXIGLhZvz48XLzzTfr01L/+I//KFu3bpWf//zn+qYUFRXJuHHj5JlnntHtclTYefLJJ3UPqLvvvjtR03P77bfrRsjqdNbZs2dlzJgxurGxbT2lvCoko1z4ujHvqodLEMswuYdUlNehrbhCOGrD9hHicHPTTTfJihUrdBuY6dOn6/Ciun6rcWvinnjiCfniiy/0uDWqhubWW2/VXb8bNWqUeM2SJUt0oOnfv7/uJTV06FA9No6NvNiY2UHylxwq8l2O+RRStY2F4rSdS+eXHnP0enjb3oj1gbD+oIoyxxfO/Pa3v61v2ajaGxV81C0b1TNq6dKlTr8acEWYam3yOaDS6Ddc1Pog4ADhwrWlEDlBXwKBmjcA8BbhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AAAg2uPcRAUDLgEA/Dqu5DLQH8NI5I5w4+EGREACANR1bEkewby21yB3hBsAAAJEjYz7aHMDAACsQrgBAABWsfa0VCHnJ6kiRF3bFee/kQnbBbzGNhbxcFPoxkPAARAkWw5ipsyHKdOJiIabD+5bkPd7O7/0mKvTAnvlu52xjUVDPttH8rZRV88ZRFNyACvkWBcF1oWbQqiNhYMPvESBZCcv1ivBBk7HwcHf0aAYAAADEHhzR7gBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKtwbaksuIaHveuUdQubt1OG6A+vQsse1m3uCDce8+JAysEZQDbJVxSnrAgPN4IJ6zN3hBsPrvabfGXxsCRttVMEMS1BfW+m6XBrnQJ+cLqdpm+jySEnKEHv/0F/f/J0FFIGUf44R7hJk8+BL9NnqI0xDDsVxJVfsW5sF4CX21j8/fEDIeVPeFD++I8GxQAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAABAdMPNlVdeKUVFRRfdRo8erZ8/deqU/n/r1q2lWbNmMnToUDl8+HDKZ+zfv18GDx4sTZo0kTZt2sjEiRPl3Llz7s4VAACILEfhZtu2bXLw4MHEbd26dfrxe++9V/8dP368vPLKK7J8+XLZuHGjfPrppzJkyJDE+8+fP6+DzZkzZ2TTpk3y4osvyuLFi2Xq1KluzxcAAIgoR+Hmsssuk7KyssRt1apV0rlzZ/n6178ux48fl4ULF8pPfvIT6devn/Tu3VsWLVqkQ8zmzX8bBnzt2rWye/du+dWvfiU9e/aUQYMGyYwZM2Tu3Lk68AAAAATW5kaFERVSvvvd7+pTUzt27JCzZ89KRUVF4jVdu3aVDh06SHV1tb6v/vbo0UPatm2beM3AgQOlpqZGdu3alfW7Tp8+rV+TfAMAAHD1wpkrV66UY8eOyUMPPaTvHzp0SBo2bCgtW7ZMeZ0KMuq5+GuSg038+fhz2VRWVsq0adPENGG4PH3yBduCmp6wXJkXgH+CLnfSpwPRknfNjToFpU4rtWvXTrw2efJkfdorfjtw4IDn32mLsOzYajrCMi0AALvlVXPz5z//WdavXy8vv/xy4jHVBkedqlK1Ocm1N6q3lHou/pqtW7emfFa8N1X8NZmUlJTom0kKuUR955ceK/iz0j8jn8/xajoAREchZSHga7hRDYVVN27V8ylONSBu0KCBVFVV6S7gyp49e3TX7/Lycn1f/Z05c6YcOXJEv19RPa5KS0ule/fuec+EbdwoDML2GYQcAEBow82FCxd0uBkxYoTUr//3t7do0UJGjhwpEyZMkFatWunAMnbsWB1o+vb92+mIAQMG6BAzfPhwmT17tm5nM2XKFD02jmk1MwAAwJJwo05HqdoY1Usq3Zw5c6S4uFjX3KgeTqon1Lx58xLP16tXT3cfHzVqlA49TZs21SFp+vTphc8JAABAPuFG1b7EYrGMzzVq1EiPWaNu2XTs2FFWr17t9GsBAABywrWlAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACr5HVtKSBf+V4ZvMv4zVxVHHCgkP1F7W+FfgYQJMINjEAhC/iH/Q2mI9zAF4VcYTz9iuJOP4srkiPKnOwv2faVQvZfIAhFsWwXigqxmpoafRXyz9//spQ2p9kQAAAmqDlxQS75yody/PhxKS0t9ex7SAYAAMAqRp6Wilc21Zy8EPSkAACAHMWP216fNDIy3Hz22Wf6b8cbPg56UgAAgEMnTpzQzUu8YmS4adWqlf67f/9+TxcOcmv/1L59ezlw4ICn509RN9ZFeLAuwoN1Ea71oI7bRUVF0q5dO0+/z8hwU1z8t6ZCKtiwsYaDWg+si3BgXYQH6yI8WBfh4NdxmwbFAADAKoQbAABgFSPDTUlJiTz11FP6L4LFuggP1kV4sC7Cg3URzfVg5CB+AAAAVtXcAAAAZEO4AQAAViHcAAAAqxBuAACAVQg3AADAKkaGm7lz58qVV14pjRo1kj59+sjWrVuDniSrVFZWyk033STNmzeXNm3ayN133y179uxJec2pU6dk9OjR0rp1a2nWrJkMHTpUDh8+nPIaNcz24MGDpUmTJvpzJk6cKOfOnfN5buzy7LPP6qHLx40bl3iMdeGfTz75RB544AG9rBs3biw9evSQ7du3J55XnU+nTp0ql19+uX6+oqJC9u7dm/IZR48elWHDhulRWlu2bCkjR46UkydPBjA3Zjp//rw8+eST0qlTJ72MO3fuLDNmzEi5ECPrwRtvvvmm3HnnnfrSCaocWrlyZcrzbi33P/7xj/K1r31NH+PVJRtmz57tfGJjhlm2bFmsYcOGsf/4j/+I7dq1K/bII4/EWrZsGTt8+HDQk2aNgQMHxhYtWhTbuXNn7J133ondcccdsQ4dOsROnjyZeM1jjz0Wa9++fayqqiq2ffv2WN++fWM333xz4vlz587Frr322lhFRUXsv//7v2OrV6+OXXrppbHJkycHNFfm27p1a+zKK6+MXXfddbHHH3888Tjrwh9Hjx6NdezYMfbQQw/FtmzZEvvwww9jr732Wmzfvn2J1zz77LOxFi1axFauXBn7wx/+EPuHf/iHWKdOnWL/93//l3jN7bffHrv++utjmzdvjv3Xf/1XrEuXLrHvfOc7Ac2VeWbOnBlr3bp1bNWqVbGPPvootnz58lizZs1iP/3pTxOvYT14Q5Ud//zP/xx7+eWXVZKMrVixIuV5N5b78ePHY23bto0NGzZMH4P+8z//M9a4cePYz372M0fTaly4+epXvxobPXp04v758+dj7dq1i1VWVgY6XTY7cuSI3pA3btyo7x87dizWoEEDXajEvffee/o11dXViZ2guLg4dujQocRr5s+fHystLY2dPn06gLkw24kTJ2JXXXVVbN26dbGvf/3riXDDuvDPpEmTYrfeemvW5y9cuBArKyuL/eu//mviMbV+SkpKdAGt7N69W6+bbdu2JV7zu9/9LlZUVBT75JNPPJ4DOwwePDj23e9+N+WxIUOG6IOhwnrwR3q4cWu5z5s3L3bJJZeklE1q37v66qsdTZ9Rp6XOnDkjO3bs0FVdyRfRVPerq6sDnTabHT9+POVq7GodnD17NmU9dO3aVTp06JBYD+qvqrJv27Zt4jUDBw7UV4bdtWuX7/NgOnXaSZ1WSl7mCuvCP7/97W/lxhtvlHvvvVef2uvVq5f84he/SDz/0UcfyaFDh1LWhbpIoDp1nrwuVFW8+pw49XpVjm3ZssXnOTLTzTffLFVVVfL+++/r+3/4wx/k97//vQwaNEjfZz0Ew63lrl5z2223ScOGDVPKK9U04vPPP7fzquB/+ctf9PnW5EJaUff/9Kc/BTZdNrtw4YJu33HLLbfItddeqx9TG7Da8NRGmr4e1HPx12RaT/HnkLtly5bJ22+/Ldu2bbvoOdaFfz788EOZP3++TJgwQX70ox/p9fH9739fL/8RI0YklmWmZZ28LlQwSla/fn39w4F1kZsf/vCHOpirEF+vXj19TJg5c6Zux6GwHoLh1nJXf1V7qvTPiD93ySWX2BduEEyNwc6dO/UvI/jvwIED8vjjj8u6det04zoEG/TVL85Zs2bp+6rmRu0bCxYs0OEG/vj1r38tS5YskaVLl8o111wj77zzjv4Bphq5sh4QZ9RpqUsvvVQn9fSeIOp+WVlZYNNlqzFjxsiqVavk9ddflyuuuCLxuFrW6hThsWPHsq4H9TfTeoo/h9yo005HjhyRG264Qf/CUbeNGzfK888/r/+vftGwLvyheoB079495bFu3brpnmjJy7K28kn9Veszmeq1pnqQsC5yo3r6qdqb+++/X59uHT58uIwfP1738lRYD8Fwa7m7VV4ZFW5U9W/v3r31+dbkX1Pqfnl5eaDTZhPVVkwFmxUrVsiGDRsuqiJU66BBgwYp60GdD1WFfHw9qL/vvvtuyoasah9U97/0AwSy69+/v16O6tdp/KZqD1QVfPz/rAt/qFOz6UMiqHYfHTt21P9X+4kqfJPXhTp9otoSJK8LFURVaI1T+5gqx1TbBNTtr3/9q26jkUz96FXLUGE9BMOt5a5eo7qcq7aEyeXV1VdfnfMpKS1mYFdw1fp68eLFuuX1o48+qruCJ/cEQWFGjRqlu/O98cYbsYMHDyZuf/3rX1O6H6vu4Rs2bNDdj8vLy/UtvfvxgAEDdHfyNWvWxC677DK6H7sgubeUwrrwryt+/fr1dVfkvXv3xpYsWRJr0qRJ7Fe/+lVKV1hVHv3mN7+J/fGPf4zdddddGbvC9urVS3cn//3vf697wdEFOXcjRoyIfelLX0p0BVfdktXQBk888UTiNawH73ptquEk1E3Fh5/85Cf6/3/+859dW+6qh5XqCj58+HDdFVwd89V+Zn1XcOWFF17Qhbka70Z1DVf95eEetdFmuqmxb+LUxvq9731Pd9lTG94999yjA1Cyjz/+ODZo0CA9RoEqfH7wgx/Ezp49G8Ac2R1uWBf+eeWVV3RQVD+wunbtGvv5z3+e8rzqDvvkk0/qwlm9pn///rE9e/akvOazzz7Thbkam0V1x3/44Yf1QQO5qamp0du/OgY0atQo9uUvf1mPvZLcdZj14I3XX38947FBBU43l7saI0cNu6A+QwVZFZqcKlL/uFMpBQAAEDyj2twAAADUhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAGKT/wfsAOOC/xvaKQAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.imshow(floorplan, interpolation='nearest')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_nY6uSJzp9B",
        "outputId": "3c6cbaf2-5ea5-4fc0-ee40-d8b63519536e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'device_id': '202194278473007104',\n",
              " 'namespace': 'PHRED',\n",
              " 'code': 'SB1:AHU:AC-2',\n",
              " 'zone_id': '',\n",
              " 'device_type': 6,\n",
              " 'observable_fields': {'building_air_static_pressure_sensor': 1,\n",
              "  'outside_air_flowrate_sensor': 1,\n",
              "  'supply_fan_speed_percentage_command': 1,\n",
              "  'supply_air_temperature_sensor': 1,\n",
              "  'supply_fan_speed_frequency_sensor': 1,\n",
              "  'supply_air_static_pressure_setpoint': 1,\n",
              "  'return_air_temperature_sensor': 1,\n",
              "  'mixed_air_temperature_setpoint': 1,\n",
              "  'exhaust_fan_speed_percentage_command': 1,\n",
              "  'exhaust_fan_speed_frequency_sensor': 1,\n",
              "  'outside_air_damper_percentage_command': 1,\n",
              "  'mixed_air_temperature_sensor': 1,\n",
              "  'exhaust_air_damper_percentage_command': 1,\n",
              "  'cooling_percentage_command': 1,\n",
              "  'outside_air_flowrate_setpoint': 1,\n",
              "  'supply_air_temperature_setpoint': 1,\n",
              "  'building_air_static_pressure_setpoint': 1,\n",
              "  'supply_air_static_pressure_sensor': 1},\n",
              " 'action_fields': {'exhaust_air_damper_percentage_command': 1,\n",
              "  'supply_air_temperature_setpoint': 1,\n",
              "  'supply_fan_speed_percentage_command': 1,\n",
              "  'outside_air_flowrate_setpoint': 1,\n",
              "  'cooling_percentage_command': 1,\n",
              "  'mixed_air_temperature_setpoint': 1,\n",
              "  'exhaust_fan_speed_percentage_command': 1,\n",
              "  'outside_air_damper_percentage_command': 1,\n",
              "  'supply_air_static_pressure_setpoint': 1,\n",
              "  'building_air_static_pressure_setpoint': 1}}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metadata[\"device_infos\"][0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWdBLwOqN1zQ",
        "outputId": "15a44d0b-9681-46fa-f773-6bdd5d3157ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'zone_id': 'rooms/1002000133978',\n",
              " 'building_id': 'buildings/3616672508',\n",
              " 'zone_description': 'SB1-2-C2054',\n",
              " 'area': 0.0,\n",
              " 'zone_type': 1,\n",
              " 'floor': 2,\n",
              " 'devices': ['2618581107144046', '2696593986887004']}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metadata[\"zone_infos\"][0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qeF5KeBpsnV",
        "outputId": "49548b36-6e05-4e76-c3b4-91878481e786"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(53292, 123)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "temp_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxgShqhKptxl",
        "outputId": "daa85e42-f38f-44ed-86fd-aa93b8d3dc91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.10406372865800263\n"
          ]
        }
      ],
      "source": [
        "print((temp_data==0).sum()/(temp_data.shape[0]*temp_data.shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lr3ZxNcp4wH",
        "outputId": "da12dd75-7f4e-4f22-9d84-daf917a8a935"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.28568066460576663"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "indexes1 = [v for k, v in metadata['observation_ids'].items() if \"zone_air_temperature_sensor\" in k]\n",
        "temp_data_train = data['observation_value_matrix'][:, indexes1]\n",
        "\n",
        "(temp_data_train==0).sum()/(temp_data_train.shape[0]*temp_data_train.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting temperature preprocessing...\n",
            "Extracting arrays from NpzFile objects...\n",
            "Training observation matrix shape: (51852, 1198)\n",
            "Validation exogenous matrix shape: (53292, 1075)\n",
            "Validation temperature matrix shape: (53292, 123)\n",
            "\n",
            "============================================================\n",
            "PREPROCESSING TRAINING DATA\n",
            "============================================================\n",
            "\n",
            "=== Temperature Preprocessing for training data ===\n",
            "Found 246 temperature sensors\n",
            "Found 357 temperature setpoints\n",
            "  Converting 36921/51852 values in 202194278473007104@return_air_temperature_sensor\n",
            "    Before: min=284.43, max=307.39\n",
            "    After:  min=52.30, max=93.64\n",
            "  Converting 36921/51852 values in 202194278473007104@mixed_air_temperature_sensor\n",
            "    Before: min=281.87, max=305.57\n",
            "    After:  min=47.69, max=90.35\n",
            "  Converting 36921/51852 values in 202194278473007104@supply_air_temperature_sensor\n",
            "    Before: min=280.11, max=305.19\n",
            "    After:  min=44.53, max=89.67\n",
            "  Converting 36758/51852 values in 2291864505572917248@outside_air_wetbulb_temperature_sensor\n",
            "    Before: min=273.01, max=293.60\n",
            "    After:  min=31.74, max=68.82\n",
            "  Converting 33690/51852 values in 2291864505572917248@outside_air_dewpoint_temperature_sensor\n",
            "    Before: min=273.00, max=290.19\n",
            "    After:  min=31.73, max=62.67\n",
            "  Converting 36876/51852 values in 2291864505572917248@outside_air_temperature_sensor\n",
            "    Before: min=273.01, max=311.09\n",
            "    After:  min=31.75, max=100.29\n",
            "  Converting 35112/51852 values in 3111519637754347520@return_water_temperature_sensor\n",
            "    Before: min=286.66, max=366.73\n",
            "    After:  min=56.32, max=200.44\n",
            "  Converting 35112/51852 values in 8729789859712991232@supply_water_temperature_sensor\n",
            "    Before: min=276.91, max=372.09\n",
            "    After:  min=38.78, max=210.09\n",
            "  Converting 35112/51852 values in 8804069566750654464@supply_water_temperature_sensor\n",
            "    Before: min=277.46, max=369.39\n",
            "    After:  min=39.76, max=205.24\n",
            "  Converting 35107/51852 values in 11251805651040468992@supply_water_temperature_sensor\n",
            "    Before: min=277.46, max=369.39\n",
            "    After:  min=39.76, max=205.24\n",
            "  Converting 36916/51852 values in 12945159110931775488@mixed_air_temperature_sensor\n",
            "    Before: min=278.42, max=306.00\n",
            "    After:  min=41.48, max=91.14\n",
            "  Converting 36916/51852 values in 12945159110931775488@return_air_temperature_sensor\n",
            "    Before: min=283.79, max=304.72\n",
            "    After:  min=51.15, max=88.83\n",
            "  Converting 36916/51852 values in 12945159110931775488@supply_air_temperature_sensor\n",
            "    Before: min=281.46, max=304.89\n",
            "    After:  min=46.96, max=89.13\n",
            "  Converting 35112/51852 values in 13761436543392677888@supply_water_temperature_sensor\n",
            "    Before: min=285.18, max=370.69\n",
            "    After:  min=53.65, max=207.57\n",
            "  Converting 35112/51852 values in 13761436543392677888@return_water_temperature_sensor\n",
            "    Before: min=286.66, max=366.73\n",
            "    After:  min=56.32, max=200.44\n",
            "  Converting 36922/51852 values in 14409954889734029312@return_air_temperature_sensor\n",
            "    Before: min=284.43, max=307.39\n",
            "    After:  min=52.30, max=93.64\n",
            "  Converting 36922/51852 values in 14409954889734029312@supply_air_temperature_sensor\n",
            "    Before: min=280.11, max=305.19\n",
            "    After:  min=44.53, max=89.67\n",
            "  Converting 36922/51852 values in 14409954889734029312@mixed_air_temperature_sensor\n",
            "    Before: min=282.11, max=305.57\n",
            "    After:  min=48.12, max=90.35\n",
            "  Converting 35112/51852 values in 14955986657738752000@supply_water_temperature_sensor\n",
            "    Before: min=276.91, max=372.09\n",
            "    After:  min=38.78, max=210.09\n",
            "  Converting 36779/51852 values in 16286830034440683520@mixed_air_temperature_sensor\n",
            "    Before: min=283.76, max=313.93\n",
            "    After:  min=51.10, max=105.40\n",
            "  Converting 36779/51852 values in 16286830034440683520@zone_air_temperature_sensor\n",
            "    Before: min=294.76, max=301.37\n",
            "    After:  min=70.90, max=82.80\n",
            "  Converting 36779/51852 values in 16286830034440683520@discharge_air_temperature_sensor\n",
            "    Before: min=276.18, max=305.31\n",
            "    After:  min=37.45, max=89.90\n",
            "  Converting 36779/51852 values in 16286830034440683520@return_air_temperature_sensor\n",
            "    Before: min=293.54, max=308.70\n",
            "    After:  min=68.70, max=96.00\n",
            "  Converting 36921/51852 values in 202194278473007104@supply_air_temperature_setpoint\n",
            "    Before: min=285.93, max=297.04\n",
            "    After:  min=55.00, max=75.00\n",
            "  Converting 36921/51852 values in 202194278473007104@mixed_air_temperature_setpoint\n",
            "    Before: min=284.81, max=295.93\n",
            "    After:  min=53.00, max=73.00\n",
            "  Converting 36916/51852 values in 12945159110931775488@supervisor_supply_air_temperature_setpoint\n",
            "    Before: min=291.48, max=291.48\n",
            "    After:  min=65.00, max=65.00\n",
            "  Converting 36916/51852 values in 12945159110931775488@mixed_air_temperature_setpoint\n",
            "    Before: min=284.81, max=295.93\n",
            "    After:  min=53.00, max=73.00\n",
            "  Converting 36916/51852 values in 12945159110931775488@program_supply_air_temperature_setpoint\n",
            "    Before: min=285.93, max=297.04\n",
            "    After:  min=55.00, max=75.00\n",
            "  Converting 36916/51852 values in 12945159110931775488@supply_air_temperature_setpoint\n",
            "    Before: min=285.93, max=297.04\n",
            "    After:  min=55.00, max=75.00\n",
            "  Converting 35112/51852 values in 13761436543392677888@supervisor_supply_water_temperature_setpoint\n",
            "    Before: min=327.59, max=327.59\n",
            "    After:  min=130.00, max=130.00\n",
            "  Converting 35112/51852 values in 13761436543392677888@supply_water_temperature_setpoint\n",
            "    Before: min=310.93, max=352.59\n",
            "    After:  min=100.00, max=175.00\n",
            "  Converting 35112/51852 values in 13761436543392677888@program_supply_water_temperature_setpoint\n",
            "    Before: min=333.15, max=369.26\n",
            "    After:  min=140.00, max=205.00\n",
            "  Converting 36922/51852 values in 14409954889734029312@mixed_air_temperature_setpoint\n",
            "    Before: min=284.81, max=295.93\n",
            "    After:  min=53.00, max=73.00\n",
            "  Converting 36922/51852 values in 14409954889734029312@program_supply_air_temperature_setpoint\n",
            "    Before: min=285.93, max=297.04\n",
            "    After:  min=55.00, max=75.00\n",
            "  Converting 36922/51852 values in 14409954889734029312@supervisor_supply_air_temperature_setpoint\n",
            "    Before: min=291.48, max=291.48\n",
            "    After:  min=65.00, max=65.00\n",
            "  Converting 36922/51852 values in 14409954889734029312@supply_air_temperature_setpoint\n",
            "    Before: min=285.93, max=297.04\n",
            "    After:  min=55.00, max=75.00\n",
            "  Converting 36779/51852 values in 16286830034440683520@zone_air_cooling_temperature_setpoint\n",
            "    Before: min=298.70, max=298.70\n",
            "    After:  min=78.00, max=78.00\n",
            "\n",
            "Conversion Summary for training data:\n",
            "  Temperature sensors converted: 23\n",
            "  Temperature setpoints converted: 14\n",
            "  Total values converted: 1343805\n",
            "\n",
            "============================================================\n",
            "PREPROCESSING VALIDATION EXOGENOUS DATA\n",
            "============================================================\n",
            "\n",
            "=== Temperature Preprocessing for validation exogenous data ===\n",
            "Found 123 temperature sensors\n",
            "Found 357 temperature setpoints\n",
            "  Converting 39124/53292 values in 202194278473007104@return_air_temperature_sensor\n",
            "    Before: min=283.89, max=312.25\n",
            "    After:  min=51.33, max=102.39\n",
            "  Converting 39124/53292 values in 202194278473007104@mixed_air_temperature_sensor\n",
            "    Before: min=280.86, max=308.40\n",
            "    After:  min=45.87, max=95.45\n",
            "  Converting 39124/53292 values in 202194278473007104@supply_air_temperature_sensor\n",
            "    Before: min=281.47, max=310.96\n",
            "    After:  min=46.98, max=100.06\n",
            "  Converting 39126/53292 values in 2291864505572917248@outside_air_wetbulb_temperature_sensor\n",
            "    Before: min=273.34, max=295.94\n",
            "    After:  min=32.34, max=73.02\n",
            "  Converting 38692/53292 values in 2291864505572917248@outside_air_dewpoint_temperature_sensor\n",
            "    Before: min=273.00, max=291.79\n",
            "    After:  min=31.73, max=65.55\n",
            "  Converting 39127/53292 values in 2291864505572917248@outside_air_temperature_sensor\n",
            "    Before: min=273.89, max=311.89\n",
            "    After:  min=33.34, max=101.74\n",
            "  Converting 42465/53292 values in 3111519637754347520@return_water_temperature_sensor\n",
            "    Before: min=287.88, max=369.87\n",
            "    After:  min=58.51, max=206.10\n",
            "  Converting 42464/53292 values in 8729789859712991232@supply_water_temperature_sensor\n",
            "    Before: min=276.93, max=371.51\n",
            "    After:  min=38.80, max=209.06\n",
            "  Converting 42464/53292 values in 8804069566750654464@supply_water_temperature_sensor\n",
            "    Before: min=277.20, max=369.73\n",
            "    After:  min=39.30, max=205.85\n",
            "  Converting 42464/53292 values in 11251805651040468992@supply_water_temperature_sensor\n",
            "    Before: min=277.20, max=369.73\n",
            "    After:  min=39.30, max=205.85\n",
            "  Converting 39127/53292 values in 12945159110931775488@mixed_air_temperature_sensor\n",
            "    Before: min=278.83, max=312.90\n",
            "    After:  min=42.23, max=103.55\n",
            "  Converting 39127/53292 values in 12945159110931775488@return_air_temperature_sensor\n",
            "    Before: min=283.23, max=313.38\n",
            "    After:  min=50.14, max=104.42\n",
            "  Converting 39127/53292 values in 12945159110931775488@supply_air_temperature_sensor\n",
            "    Before: min=282.13, max=315.68\n",
            "    After:  min=48.16, max=108.56\n",
            "  Converting 42465/53292 values in 13761436543392677888@supply_water_temperature_sensor\n",
            "    Before: min=287.69, max=367.33\n",
            "    After:  min=58.18, max=201.53\n",
            "  Converting 42465/53292 values in 13761436543392677888@return_water_temperature_sensor\n",
            "    Before: min=287.88, max=369.87\n",
            "    After:  min=58.51, max=206.10\n",
            "  Converting 39124/53292 values in 14409954889734029312@return_air_temperature_sensor\n",
            "    Before: min=283.89, max=312.25\n",
            "    After:  min=51.33, max=102.39\n",
            "  Converting 39124/53292 values in 14409954889734029312@supply_air_temperature_sensor\n",
            "    Before: min=281.47, max=310.96\n",
            "    After:  min=46.98, max=100.06\n",
            "  Converting 39124/53292 values in 14409954889734029312@mixed_air_temperature_sensor\n",
            "    Before: min=280.86, max=308.40\n",
            "    After:  min=45.87, max=95.45\n",
            "  Converting 42464/53292 values in 14955986657738752000@supply_water_temperature_sensor\n",
            "    Before: min=276.93, max=371.51\n",
            "    After:  min=38.80, max=209.06\n",
            "  Converting 47946/53292 values in 16286830034440683520@mixed_air_temperature_sensor\n",
            "    Before: min=284.37, max=312.15\n",
            "    After:  min=52.20, max=102.20\n",
            "  Converting 47946/53292 values in 16286830034440683520@discharge_air_temperature_sensor\n",
            "    Before: min=276.56, max=304.95\n",
            "    After:  min=38.15, max=89.25\n",
            "  Converting 47946/53292 values in 16286830034440683520@return_air_temperature_sensor\n",
            "    Before: min=292.81, max=308.70\n",
            "    After:  min=67.40, max=96.00\n",
            "  Converting 39127/53292 values in 202194278473007104@supply_air_temperature_setpoint\n",
            "    Before: min=285.00, max=297.04\n",
            "    After:  min=53.34, max=75.00\n",
            "  Converting 39127/53292 values in 202194278473007104@mixed_air_temperature_setpoint\n",
            "    Before: min=283.89, max=295.93\n",
            "    After:  min=51.34, max=73.00\n",
            "  Converting 39127/53292 values in 12945159110931775488@supervisor_supply_air_temperature_setpoint\n",
            "    Before: min=285.00, max=416.65\n",
            "    After:  min=53.33, max=290.29\n",
            "  Converting 39127/53292 values in 12945159110931775488@mixed_air_temperature_setpoint\n",
            "    Before: min=283.89, max=296.77\n",
            "    After:  min=51.33, max=74.52\n",
            "  Converting 39127/53292 values in 12945159110931775488@program_supply_air_temperature_setpoint\n",
            "    Before: min=285.93, max=297.04\n",
            "    After:  min=55.00, max=75.00\n",
            "  Converting 39127/53292 values in 12945159110931775488@supply_air_temperature_setpoint\n",
            "    Before: min=285.00, max=297.89\n",
            "    After:  min=53.33, max=76.52\n",
            "  Converting 42464/53292 values in 13761436543392677888@supervisor_supply_water_temperature_setpoint\n",
            "    Before: min=310.00, max=355.00\n",
            "    After:  min=98.33, max=179.33\n",
            "  Converting 42466/53292 values in 13761436543392677888@supply_water_temperature_setpoint\n",
            "    Before: min=310.00, max=352.59\n",
            "    After:  min=98.33, max=175.00\n",
            "  Converting 42318/53292 values in 13761436543392677888@program_supply_water_temperature_setpoint\n",
            "    Before: min=333.15, max=369.26\n",
            "    After:  min=140.00, max=205.00\n",
            "  Converting 39127/53292 values in 14409954889734029312@mixed_air_temperature_setpoint\n",
            "    Before: min=283.89, max=295.93\n",
            "    After:  min=51.34, max=73.00\n",
            "  Converting 39127/53292 values in 14409954889734029312@program_supply_air_temperature_setpoint\n",
            "    Before: min=285.93, max=297.04\n",
            "    After:  min=55.00, max=75.00\n",
            "  Converting 39127/53292 values in 14409954889734029312@supervisor_supply_air_temperature_setpoint\n",
            "    Before: min=285.00, max=416.56\n",
            "    After:  min=53.33, max=290.14\n",
            "  Converting 39127/53292 values in 14409954889734029312@supply_air_temperature_setpoint\n",
            "    Before: min=285.00, max=297.04\n",
            "    After:  min=53.34, max=75.00\n",
            "  Converting 47946/53292 values in 16286830034440683520@zone_air_cooling_temperature_setpoint\n",
            "    Before: min=298.70, max=298.70\n",
            "    After:  min=78.00, max=78.00\n",
            "\n",
            "Conversion Summary for validation exogenous data:\n",
            "  Temperature sensors converted: 22\n",
            "  Temperature setpoints converted: 14\n",
            "  Total values converted: 1476623\n",
            "\n",
            "============================================================\n",
            "PREPROCESSING VALIDATION TEMPERATURE DATA (TARGETS)\n",
            "============================================================\n",
            "\n",
            "=== Temperature Preprocessing for validation temperature targets ===\n",
            "  Converting 47946/53292 values in 16286830034440683520@zone_air_temperature_sensor\n",
            "    Before: min=295.87, max=305.37\n",
            "    After:  min=72.90, max=90.00\n",
            "\n",
            "Conversion Summary for validation temperature targets:\n",
            "  Temperature sensors converted: 1\n",
            "  Total values converted: 47946\n",
            "\n",
            "============================================================\n",
            "REMOVING ZERO TEMPERATURE READINGS\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "REMOVING ZERO TEMPERATURE READINGS\n",
            "============================================================\n",
            "\n",
            "Cleaning training data...\n",
            "  Original training data: 51852 rows\n",
            "  Rows with zero temperatures: 16350\n",
            "  Rows to keep: 35502\n",
            "  Percentage kept: 68.5%\n",
            "\n",
            "Cleaning validation data...\n",
            "  Original validation data: 53292 rows\n",
            "  Rows with zero temperatures: 19415\n",
            "  Rows to keep: 33877\n",
            "  Percentage kept: 63.6%\n",
            "\n",
            "Data cleaning summary:\n",
            "  Training: 51852 -> 35502 rows\n",
            "  Validation: 53292 -> 33877 rows\n",
            "\n",
            "============================================================\n",
            "TEMPERATURE PREPROCESSING COMPLETED\n",
            "============================================================\n",
            "\n",
            "OVERALL CONVERSION SUMMARY:\n",
            "  Training data: 1343805 values converted\n",
            "  Validation exogenous: 1476623 values converted\n",
            "  Validation targets: 47946 values converted\n",
            "  TOTAL: 2868374 temperature values converted from Kelvin to Fahrenheit\n",
            "\n",
            "OVERALL ZERO REMOVAL SUMMARY:\n",
            "  Training data: 51852 -> 35502 rows\n",
            "  Validation data: 53292 -> 33877 rows\n",
            "\n",
            "Updating global variables with cleaned and preprocessed data...\n",
            "Preprocessing complete! Now starting model training with Grouped PCA...\n",
            "Initializing Smart Buildings Predictor with Grouped PCA...\n",
            "Preparing training data...\n",
            "Fitted imputer on training data (found 0 NaN values, 0.00%)\n",
            "NaN values after imputation: 0\n",
            "\n",
            "Fitting Grouped PCA (max 15 components per group)...\n",
            "Creating feature groups based on domain knowledge...\n",
            "Feature groups created:\n",
            "  air_temperatures: 221 features\n",
            "  water_temperatures: 12 features\n",
            "  setpoints: 416 features\n",
            "  control_commands: 249 features\n",
            "  environmental: 15 features\n",
            "  flow_pressure: 122 features\n",
            "  other: 40 features\n",
            "  Total features categorized: 1075/1075\n",
            "  air_temperatures: 221 features → 15 components (explained variance: 0.863)\n",
            "  water_temperatures: 12 features → 12 components (explained variance: 1.000)\n",
            "  setpoints: 416 features → 15 components (explained variance: 0.999)\n",
            "  control_commands: 249 features → 15 components (explained variance: 0.943)\n",
            "  environmental: 15 features → 15 components (explained variance: 1.000)\n",
            "  flow_pressure: 122 features → 15 components (explained variance: 0.936)\n",
            "  other: 40 features → 15 components (explained variance: 0.916)\n",
            "\n",
            "Grouped PCA Summary:\n",
            "  Original features: 1075\n",
            "  Total PCA components: 102\n",
            "  Feature groups: 7\n",
            "  Dimensionality reduction: 1075 → 102\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-06 02:13:11,893] A new study created in memory with name: hour_0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data shape: X=(35502, 119), y=(35502, 123)\n",
            "Feature names: 119 features\n",
            "Training 24 hourly models...\n",
            "Training model for hour 0...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-06 02:14:35,674] Trial 0 finished with value: 1.428215325055329 and parameters: {'n_estimators': 105, 'max_depth': 7, 'learning_rate': 0.29486705746568753, 'subsample': 0.7119674331203699, 'colsample_bytree': 0.7910763321709807, 'reg_alpha': 3.686206610809941, 'reg_lambda': 5.05254228906335}. Best is trial 0 with value: 1.428215325055329.\n",
            "[I 2025-07-06 02:16:38,950] Trial 1 finished with value: 1.3837706938000678 and parameters: {'n_estimators': 148, 'max_depth': 7, 'learning_rate': 0.24717934899140243, 'subsample': 0.7784571663986545, 'colsample_bytree': 0.8430620458232236, 'reg_alpha': 2.6697309223623917, 'reg_lambda': 6.436853529573526}. Best is trial 1 with value: 1.3837706938000678.\n",
            "[I 2025-07-06 02:21:32,379] Trial 2 finished with value: 1.4047803025598944 and parameters: {'n_estimators': 412, 'max_depth': 7, 'learning_rate': 0.29485666312161224, 'subsample': 0.8898400035230203, 'colsample_bytree': 0.6822745735855745, 'reg_alpha': 2.02485015629368, 'reg_lambda': 0.388599518384459}. Best is trial 1 with value: 1.3837706938000678.\n",
            "[I 2025-07-06 02:24:48,894] Trial 3 finished with value: 1.6153077633149107 and parameters: {'n_estimators': 455, 'max_depth': 5, 'learning_rate': 0.015588298544225831, 'subsample': 0.8471784119933283, 'colsample_bytree': 0.9356725972390824, 'reg_alpha': 9.244635605585831, 'reg_lambda': 4.645649655304963}. Best is trial 1 with value: 1.3837706938000678.\n",
            "[I 2025-07-06 02:26:06,380] Trial 4 finished with value: 1.6739598560366016 and parameters: {'n_estimators': 114, 'max_depth': 7, 'learning_rate': 0.07888423784174663, 'subsample': 0.6072198379175583, 'colsample_bytree': 0.7144921543432854, 'reg_alpha': 9.01064427924281, 'reg_lambda': 1.2454201276616534}. Best is trial 1 with value: 1.3837706938000678.\n",
            "[I 2025-07-06 02:28:14,160] A new study created in memory with name: hour_1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hour 0 - Best MAE: 1.3838\n",
            "Training model for hour 1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-06 02:31:44,395] Trial 0 finished with value: 1.621796654430736 and parameters: {'n_estimators': 448, 'max_depth': 5, 'learning_rate': 0.29305277760890064, 'subsample': 0.7892676406213743, 'colsample_bytree': 0.9319758143520563, 'reg_alpha': 6.573066392741979, 'reg_lambda': 1.3153940174382575}. Best is trial 0 with value: 1.621796654430736.\n",
            "[I 2025-07-06 02:32:36,076] Trial 1 finished with value: 1.7561669697920426 and parameters: {'n_estimators': 101, 'max_depth': 5, 'learning_rate': 0.17449893717307072, 'subsample': 0.7050270517347372, 'colsample_bytree': 0.9745681864431287, 'reg_alpha': 6.859838154648385, 'reg_lambda': 4.455768619658992}. Best is trial 0 with value: 1.621796654430736.\n",
            "[I 2025-07-06 02:36:04,254] Trial 2 finished with value: 1.7519469595310355 and parameters: {'n_estimators': 285, 'max_depth': 7, 'learning_rate': 0.046410152607344865, 'subsample': 0.9055830447685294, 'colsample_bytree': 0.607204479573222, 'reg_alpha': 4.866088109351316, 'reg_lambda': 8.17862255105354}. Best is trial 0 with value: 1.621796654430736.\n",
            "[I 2025-07-06 02:41:58,737] Trial 3 finished with value: 1.6319755783570284 and parameters: {'n_estimators': 491, 'max_depth': 7, 'learning_rate': 0.2290687025616501, 'subsample': 0.8426887889535513, 'colsample_bytree': 0.6041340915152602, 'reg_alpha': 0.6488325719202168, 'reg_lambda': 2.638243555533468}. Best is trial 0 with value: 1.621796654430736.\n",
            "[I 2025-07-06 02:48:29,289] Trial 4 finished with value: 1.487078264372518 and parameters: {'n_estimators': 316, 'max_depth': 8, 'learning_rate': 0.16747650500396652, 'subsample': 0.8167963851143345, 'colsample_bytree': 0.9758393556522914, 'reg_alpha': 5.899204308546189, 'reg_lambda': 6.553512849029621}. Best is trial 4 with value: 1.487078264372518.\n",
            "[I 2025-07-06 02:55:19,586] A new study created in memory with name: hour_2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hour 1 - Best MAE: 1.4871\n",
            "Training model for hour 2...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-06 02:59:27,266] Trial 0 finished with value: 1.6947477624234255 and parameters: {'n_estimators': 440, 'max_depth': 6, 'learning_rate': 0.06741321443770114, 'subsample': 0.8438924170927966, 'colsample_bytree': 0.6202959229418231, 'reg_alpha': 1.765034524914484, 'reg_lambda': 4.739931762935989}. Best is trial 0 with value: 1.6947477624234255.\n",
            "[I 2025-07-06 03:00:33,651] Trial 1 finished with value: 1.910179911204716 and parameters: {'n_estimators': 112, 'max_depth': 6, 'learning_rate': 0.07415816475769356, 'subsample': 0.8579011880945873, 'colsample_bytree': 0.7840945786569666, 'reg_alpha': 6.8678446152086385, 'reg_lambda': 5.764972750446067}. Best is trial 0 with value: 1.6947477624234255.\n",
            "[I 2025-07-06 03:02:49,484] Trial 2 finished with value: 1.7038919103900472 and parameters: {'n_estimators': 303, 'max_depth': 5, 'learning_rate': 0.16191036114061394, 'subsample': 0.7767861344989363, 'colsample_bytree': 0.8438373935137256, 'reg_alpha': 1.8051542821575213, 'reg_lambda': 4.57250934564492}. Best is trial 0 with value: 1.6947477624234255.\n",
            "[I 2025-07-06 03:09:21,449] Trial 3 finished with value: 1.546617117623727 and parameters: {'n_estimators': 498, 'max_depth': 7, 'learning_rate': 0.28788681440138125, 'subsample': 0.9059906358769706, 'colsample_bytree': 0.7121018916022664, 'reg_alpha': 1.5266706537772843, 'reg_lambda': 2.6494799377102645}. Best is trial 3 with value: 1.546617117623727.\n",
            "[I 2025-07-06 03:13:24,750] Trial 4 finished with value: 1.6063079132198892 and parameters: {'n_estimators': 371, 'max_depth': 6, 'learning_rate': 0.19222682304304411, 'subsample': 0.9608565940659479, 'colsample_bytree': 0.881352258275281, 'reg_alpha': 3.664593326199096, 'reg_lambda': 4.615333345069976}. Best is trial 3 with value: 1.546617117623727.\n",
            "[I 2025-07-06 03:19:31,503] A new study created in memory with name: hour_3\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hour 2 - Best MAE: 1.5466\n",
            "Training model for hour 3...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-06 03:20:59,007] Trial 0 finished with value: 2.0097520777270867 and parameters: {'n_estimators': 313, 'max_depth': 3, 'learning_rate': 0.07682085066472752, 'subsample': 0.8671997703186352, 'colsample_bytree': 0.9679588746520972, 'reg_alpha': 6.568030422573455, 'reg_lambda': 1.8484135185618875}. Best is trial 0 with value: 2.0097520777270867.\n",
            "[I 2025-07-06 03:26:42,451] Trial 1 finished with value: 1.8674095029491309 and parameters: {'n_estimators': 457, 'max_depth': 7, 'learning_rate': 0.17156773379954854, 'subsample': 0.6255693085195742, 'colsample_bytree': 0.6406335202175243, 'reg_alpha': 0.1360687385335384, 'reg_lambda': 7.9375220397128885}. Best is trial 1 with value: 1.8674095029491309.\n",
            "[I 2025-07-06 03:33:44,499] Trial 2 finished with value: 1.9851313386203138 and parameters: {'n_estimators': 497, 'max_depth': 7, 'learning_rate': 0.29919370624563246, 'subsample': 0.91284131362749, 'colsample_bytree': 0.8040188217226178, 'reg_alpha': 9.648602527465416, 'reg_lambda': 0.1586661825035811}. Best is trial 1 with value: 1.8674095029491309.\n",
            "[I 2025-07-06 03:34:57,216] Trial 3 finished with value: 2.0602565955744434 and parameters: {'n_estimators': 263, 'max_depth': 3, 'learning_rate': 0.10899561480132541, 'subsample': 0.6132719643851016, 'colsample_bytree': 0.8522244721600525, 'reg_alpha': 7.112559500365405, 'reg_lambda': 4.168018193108358}. Best is trial 1 with value: 1.8674095029491309.\n",
            "[I 2025-07-06 03:40:03,274] Trial 4 finished with value: 1.9051952813158437 and parameters: {'n_estimators': 478, 'max_depth': 6, 'learning_rate': 0.18965726491601773, 'subsample': 0.7656616299881863, 'colsample_bytree': 0.7397129197471832, 'reg_alpha': 4.874793647424605, 'reg_lambda': 1.4254194871697647}. Best is trial 1 with value: 1.8674095029491309.\n",
            "[I 2025-07-06 03:45:41,055] A new study created in memory with name: hour_4\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hour 3 - Best MAE: 1.8674\n",
            "Training model for hour 4...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-06 03:47:30,001] Trial 0 finished with value: 2.029502691675637 and parameters: {'n_estimators': 223, 'max_depth': 5, 'learning_rate': 0.06504325934544167, 'subsample': 0.7266628132971836, 'colsample_bytree': 0.9444815500530295, 'reg_alpha': 5.382005451125311, 'reg_lambda': 7.682264700581028}. Best is trial 0 with value: 2.029502691675637.\n",
            "[I 2025-07-06 03:52:49,366] Trial 1 finished with value: 2.0824938804529616 and parameters: {'n_estimators': 322, 'max_depth': 8, 'learning_rate': 0.22136187119230866, 'subsample': 0.861394244513652, 'colsample_bytree': 0.6538249841384616, 'reg_alpha': 8.041691345994941, 'reg_lambda': 4.31827843024293}. Best is trial 0 with value: 2.029502691675637.\n",
            "[I 2025-07-06 03:55:19,875] Trial 2 finished with value: 2.076256209471821 and parameters: {'n_estimators': 184, 'max_depth': 7, 'learning_rate': 0.26017407568843764, 'subsample': 0.6975362107336072, 'colsample_bytree': 0.7115699512468684, 'reg_alpha': 6.658900160717305, 'reg_lambda': 1.4969019076247556}. Best is trial 0 with value: 2.029502691675637.\n",
            "[I 2025-07-06 03:56:06,667] Trial 3 finished with value: 2.1931049142493926 and parameters: {'n_estimators': 124, 'max_depth': 4, 'learning_rate': 0.07722229778788335, 'subsample': 0.6609362096997948, 'colsample_bytree': 0.9368005649994787, 'reg_alpha': 9.047101977201173, 'reg_lambda': 4.664514733906142}. Best is trial 0 with value: 2.029502691675637.\n",
            "[I 2025-07-06 03:59:53,047] Trial 4 finished with value: 1.8936797755922474 and parameters: {'n_estimators': 280, 'max_depth': 7, 'learning_rate': 0.2622072845648422, 'subsample': 0.8147552670842915, 'colsample_bytree': 0.792946925377161, 'reg_alpha': 1.2199202004140526, 'reg_lambda': 1.072479699924178}. Best is trial 4 with value: 1.8936797755922474.\n",
            "[I 2025-07-06 04:03:15,144] A new study created in memory with name: hour_5\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hour 4 - Best MAE: 1.8937\n",
            "Training model for hour 5...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-06 04:04:57,121] Trial 0 finished with value: 1.8059192604074916 and parameters: {'n_estimators': 290, 'max_depth': 4, 'learning_rate': 0.2330845684466652, 'subsample': 0.9461146219435568, 'colsample_bytree': 0.7625012812401979, 'reg_alpha': 6.3831184481910155, 'reg_lambda': 9.347169200527095}. Best is trial 0 with value: 1.8059192604074916.\n",
            "[I 2025-07-06 04:11:48,321] Trial 1 finished with value: 1.7318304141853202 and parameters: {'n_estimators': 453, 'max_depth': 7, 'learning_rate': 0.09555421844978008, 'subsample': 0.9574113953316251, 'colsample_bytree': 0.9583522000103234, 'reg_alpha': 6.547421920709712, 'reg_lambda': 5.207981725655977}. Best is trial 1 with value: 1.7318304141853202.\n",
            "[I 2025-07-06 04:15:25,501] Trial 2 finished with value: 1.9615050366921263 and parameters: {'n_estimators': 266, 'max_depth': 8, 'learning_rate': 0.02349846131233146, 'subsample': 0.881468223303246, 'colsample_bytree': 0.6430883199701947, 'reg_alpha': 2.3216257411592056, 'reg_lambda': 4.41676223311649}. Best is trial 1 with value: 1.7318304141853202.\n",
            "[I 2025-07-06 04:18:53,005] Trial 3 finished with value: 1.7789249763876984 and parameters: {'n_estimators': 243, 'max_depth': 7, 'learning_rate': 0.15914440216650474, 'subsample': 0.9526139805549163, 'colsample_bytree': 0.7503791289747711, 'reg_alpha': 4.664930609525879, 'reg_lambda': 0.880766623987356}. Best is trial 1 with value: 1.7318304141853202.\n",
            "[I 2025-07-06 04:20:53,052] Trial 4 finished with value: 1.7805211914971664 and parameters: {'n_estimators': 171, 'max_depth': 6, 'learning_rate': 0.229846609674859, 'subsample': 0.8819516778514291, 'colsample_bytree': 0.966298163216142, 'reg_alpha': 5.957045185641827, 'reg_lambda': 1.1877519311818039}. Best is trial 1 with value: 1.7318304141853202.\n",
            "[I 2025-07-06 04:27:46,010] A new study created in memory with name: hour_6\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hour 5 - Best MAE: 1.7318\n",
            "Training model for hour 6...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-06 04:29:27,682] Trial 0 finished with value: 1.5946223373061743 and parameters: {'n_estimators': 299, 'max_depth': 4, 'learning_rate': 0.15274858551674475, 'subsample': 0.7669846345037633, 'colsample_bytree': 0.7796886799241077, 'reg_alpha': 1.5035276103565005, 'reg_lambda': 1.560017424323066}. Best is trial 0 with value: 1.5946223373061743.\n",
            "[I 2025-07-06 04:30:24,822] Trial 1 finished with value: 1.6472372669235371 and parameters: {'n_estimators': 208, 'max_depth': 3, 'learning_rate': 0.1484805035544387, 'subsample': 0.6221294997417199, 'colsample_bytree': 0.757861767705355, 'reg_alpha': 1.1645768076114766, 'reg_lambda': 6.882275664291068}. Best is trial 0 with value: 1.5946223373061743.\n",
            "[I 2025-07-06 04:36:41,288] Trial 2 finished with value: 1.5993277085111401 and parameters: {'n_estimators': 415, 'max_depth': 7, 'learning_rate': 0.18742352325261064, 'subsample': 0.9598755440774616, 'colsample_bytree': 0.854614671902589, 'reg_alpha': 2.1856176020006797, 'reg_lambda': 3.8299222223862026}. Best is trial 0 with value: 1.5946223373061743.\n",
            "[I 2025-07-06 04:43:16,531] Trial 3 finished with value: 1.6572660351542374 and parameters: {'n_estimators': 326, 'max_depth': 8, 'learning_rate': 0.2668068542133078, 'subsample': 0.9547618841721595, 'colsample_bytree': 0.8275449530191701, 'reg_alpha': 4.102964026020344, 'reg_lambda': 1.2451086902176953}. Best is trial 0 with value: 1.5946223373061743.\n",
            "[I 2025-07-06 04:46:13,457] Trial 4 finished with value: 1.657072019920239 and parameters: {'n_estimators': 494, 'max_depth': 4, 'learning_rate': 0.21739178366339126, 'subsample': 0.9229344245941747, 'colsample_bytree': 0.9067375494207109, 'reg_alpha': 6.3059574130618365, 'reg_lambda': 5.033753741829896}. Best is trial 0 with value: 1.5946223373061743.\n",
            "[I 2025-07-06 04:47:53,775] A new study created in memory with name: hour_7\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hour 6 - Best MAE: 1.5946\n",
            "Training model for hour 7...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-06 04:49:06,509] Trial 0 finished with value: 1.8667231662352899 and parameters: {'n_estimators': 155, 'max_depth': 5, 'learning_rate': 0.19804473765608602, 'subsample': 0.797631837061213, 'colsample_bytree': 0.6610536616731458, 'reg_alpha': 7.927476965834872, 'reg_lambda': 8.641316863471195}. Best is trial 0 with value: 1.8667231662352899.\n",
            "[I 2025-07-06 04:50:52,007] Trial 1 finished with value: 1.8607205580011692 and parameters: {'n_estimators': 186, 'max_depth': 6, 'learning_rate': 0.055401024205836064, 'subsample': 0.831637784418218, 'colsample_bytree': 0.7210576468242563, 'reg_alpha': 7.49851176606486, 'reg_lambda': 0.4189420996625306}. Best is trial 1 with value: 1.8607205580011692.\n",
            "[I 2025-07-06 04:53:19,700] Trial 2 finished with value: 1.689483050035183 and parameters: {'n_estimators': 421, 'max_depth': 4, 'learning_rate': 0.05849379810453526, 'subsample': 0.6741607604653513, 'colsample_bytree': 0.8980281427968928, 'reg_alpha': 2.9989452700289974, 'reg_lambda': 4.634248334142844}. Best is trial 2 with value: 1.689483050035183.\n",
            "[I 2025-07-06 04:55:55,736] Trial 3 finished with value: 1.7507301168041136 and parameters: {'n_estimators': 148, 'max_depth': 8, 'learning_rate': 0.14019377268787353, 'subsample': 0.6570941168177109, 'colsample_bytree': 0.8182007054816823, 'reg_alpha': 1.9206374084530766, 'reg_lambda': 5.600797723628001}. Best is trial 2 with value: 1.689483050035183.\n",
            "[I 2025-07-06 04:56:50,851] Trial 4 finished with value: 2.0656148541523094 and parameters: {'n_estimators': 125, 'max_depth': 5, 'learning_rate': 0.04367632437299759, 'subsample': 0.9284227323089914, 'colsample_bytree': 0.7164624651372982, 'reg_alpha': 8.150935543564524, 'reg_lambda': 7.615228863425995}. Best is trial 2 with value: 1.689483050035183.\n",
            "[I 2025-07-06 04:59:19,488] A new study created in memory with name: hour_8\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hour 7 - Best MAE: 1.6895\n",
            "Training model for hour 8...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-06 05:01:28,706] Trial 0 finished with value: 1.7380934636704468 and parameters: {'n_estimators': 207, 'max_depth': 6, 'learning_rate': 0.08191116165704444, 'subsample': 0.706184946791576, 'colsample_bytree': 0.9217217118469836, 'reg_alpha': 0.26723059875662913, 'reg_lambda': 8.148659415792388}. Best is trial 0 with value: 1.7380934636704468.\n",
            "[I 2025-07-06 05:06:23,479] Trial 1 finished with value: 1.7686143431243688 and parameters: {'n_estimators': 299, 'max_depth': 7, 'learning_rate': 0.29640716615813906, 'subsample': 0.7521001912417988, 'colsample_bytree': 0.9622623935950652, 'reg_alpha': 4.11709862158999, 'reg_lambda': 8.56050979527538}. Best is trial 0 with value: 1.7380934636704468.\n",
            "[I 2025-07-06 05:10:28,684] Trial 2 finished with value: 1.8119254204432964 and parameters: {'n_estimators': 318, 'max_depth': 7, 'learning_rate': 0.05488189515889396, 'subsample': 0.73255660446535, 'colsample_bytree': 0.8509882194421472, 'reg_alpha': 9.166454690377849, 'reg_lambda': 0.6870166700751099}. Best is trial 0 with value: 1.7380934636704468.\n",
            "[I 2025-07-06 05:11:50,665] Trial 3 finished with value: 1.832247573258514 and parameters: {'n_estimators': 176, 'max_depth': 5, 'learning_rate': 0.2059411354064902, 'subsample': 0.9058651986347567, 'colsample_bytree': 0.6398427686495756, 'reg_alpha': 5.728021483063371, 'reg_lambda': 2.073311446775536}. Best is trial 0 with value: 1.7380934636704468.\n",
            "[I 2025-07-06 05:13:04,331] Trial 4 finished with value: 1.7982975345561718 and parameters: {'n_estimators': 264, 'max_depth': 3, 'learning_rate': 0.059355219321128735, 'subsample': 0.811620825576096, 'colsample_bytree': 0.9116401086646269, 'reg_alpha': 6.04832352808955, 'reg_lambda': 7.119977213725978}. Best is trial 0 with value: 1.7380934636704468.\n",
            "[I 2025-07-06 05:15:12,086] A new study created in memory with name: hour_9\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hour 8 - Best MAE: 1.7381\n",
            "Training model for hour 9...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-06 05:19:47,062] Trial 0 finished with value: 1.7778088390608795 and parameters: {'n_estimators': 424, 'max_depth': 6, 'learning_rate': 0.09652565086967768, 'subsample': 0.7659093894807922, 'colsample_bytree': 0.7791988577268507, 'reg_alpha': 2.9514683471039365, 'reg_lambda': 7.863352097324488}. Best is trial 0 with value: 1.7778088390608795.\n",
            "[I 2025-07-06 05:28:55,511] Trial 1 finished with value: 1.8482695923554544 and parameters: {'n_estimators': 481, 'max_depth': 8, 'learning_rate': 0.19947038074401377, 'subsample': 0.9838948442939278, 'colsample_bytree': 0.6711635690263706, 'reg_alpha': 4.654180192751143, 'reg_lambda': 3.552764832468544}. Best is trial 0 with value: 1.7778088390608795.\n",
            "[I 2025-07-06 05:29:29,251] Trial 2 finished with value: 1.9480921958116983 and parameters: {'n_estimators': 111, 'max_depth': 3, 'learning_rate': 0.05596115996095143, 'subsample': 0.8605342249476946, 'colsample_bytree': 0.812546665584848, 'reg_alpha': 0.1048304159173529, 'reg_lambda': 2.887461664232858}. Best is trial 0 with value: 1.7778088390608795.\n",
            "[I 2025-07-06 05:31:59,327] Trial 3 finished with value: 1.7465558101540335 and parameters: {'n_estimators': 417, 'max_depth': 4, 'learning_rate': 0.21223440746860434, 'subsample': 0.9416887951893232, 'colsample_bytree': 0.8426139873487402, 'reg_alpha': 5.609221765549222, 'reg_lambda': 5.75815395469313}. Best is trial 3 with value: 1.7465558101540335.\n",
            "[I 2025-07-06 05:36:56,305] Trial 4 finished with value: 1.8713266388559728 and parameters: {'n_estimators': 487, 'max_depth': 6, 'learning_rate': 0.08495364202366866, 'subsample': 0.627674737123079, 'colsample_bytree': 0.633155435437394, 'reg_alpha': 4.065504668831921, 'reg_lambda': 8.710013558241178}. Best is trial 3 with value: 1.7465558101540335.\n",
            "[I 2025-07-06 05:39:25,017] A new study created in memory with name: hour_10\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hour 9 - Best MAE: 1.7466\n",
            "Training model for hour 10...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-06 05:45:54,368] Trial 0 finished with value: 2.034115663178539 and parameters: {'n_estimators': 371, 'max_depth': 8, 'learning_rate': 0.29831357040845813, 'subsample': 0.6233251760935606, 'colsample_bytree': 0.8045858835949934, 'reg_alpha': 7.0336334066989545, 'reg_lambda': 5.845597909229907}. Best is trial 0 with value: 2.034115663178539.\n",
            "[I 2025-07-06 05:46:46,739] Trial 1 finished with value: 2.0339484277961817 and parameters: {'n_estimators': 184, 'max_depth': 3, 'learning_rate': 0.046155438716028986, 'subsample': 0.8236861422864927, 'colsample_bytree': 0.8747747474201066, 'reg_alpha': 7.897984020167945, 'reg_lambda': 1.3045925284543303}. Best is trial 1 with value: 2.0339484277961817.\n",
            "[I 2025-07-06 05:49:29,637] Trial 2 finished with value: 1.8739108163775837 and parameters: {'n_estimators': 354, 'max_depth': 5, 'learning_rate': 0.05137575615280548, 'subsample': 0.8665447564058603, 'colsample_bytree': 0.8376221507201735, 'reg_alpha': 0.08588967743081476, 'reg_lambda': 8.98508816426639}. Best is trial 2 with value: 1.8739108163775837.\n",
            "[I 2025-07-06 05:51:45,823] Trial 3 finished with value: 2.0891448713929694 and parameters: {'n_estimators': 162, 'max_depth': 7, 'learning_rate': 0.2701989640690909, 'subsample': 0.8043093969164457, 'colsample_bytree': 0.7323687681708597, 'reg_alpha': 8.218117523421512, 'reg_lambda': 9.814774233042925}. Best is trial 2 with value: 1.8739108163775837.\n",
            "[I 2025-07-06 05:53:51,646] Trial 4 finished with value: 2.212370020730696 and parameters: {'n_estimators': 136, 'max_depth': 8, 'learning_rate': 0.05352130360777794, 'subsample': 0.7088663791111328, 'colsample_bytree': 0.8739575676216367, 'reg_alpha': 8.501147075190838, 'reg_lambda': 7.302338890112285}. Best is trial 2 with value: 1.8739108163775837.\n",
            "[I 2025-07-06 05:56:28,997] A new study created in memory with name: hour_11\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hour 10 - Best MAE: 1.8739\n",
            "Training model for hour 11...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-06 05:59:21,757] Trial 0 finished with value: 1.9887003370243408 and parameters: {'n_estimators': 479, 'max_depth': 4, 'learning_rate': 0.1612126802150458, 'subsample': 0.8662009089117677, 'colsample_bytree': 0.9499352704413383, 'reg_alpha': 3.5983803408779385, 'reg_lambda': 0.502777281987058}. Best is trial 0 with value: 1.9887003370243408.\n",
            "[I 2025-07-06 06:02:35,255] Trial 1 finished with value: 2.0751038689464396 and parameters: {'n_estimators': 413, 'max_depth': 5, 'learning_rate': 0.14847927122386373, 'subsample': 0.9088216884999812, 'colsample_bytree': 0.7522202918755516, 'reg_alpha': 3.7755430694534193, 'reg_lambda': 4.96197302714883}. Best is trial 0 with value: 1.9887003370243408.\n",
            "[I 2025-07-06 06:03:36,531] Trial 2 finished with value: 2.154832168749678 and parameters: {'n_estimators': 218, 'max_depth': 3, 'learning_rate': 0.24186400745707692, 'subsample': 0.6336316214314238, 'colsample_bytree': 0.6956772753459675, 'reg_alpha': 7.0455096163178395, 'reg_lambda': 9.363748473857887}. Best is trial 0 with value: 1.9887003370243408.\n",
            "[I 2025-07-06 06:07:12,652] Trial 3 finished with value: 2.2135414385642567 and parameters: {'n_estimators': 465, 'max_depth': 5, 'learning_rate': 0.18706694108002725, 'subsample': 0.9572833898526196, 'colsample_bytree': 0.6584628960073736, 'reg_alpha': 9.749194508679025, 'reg_lambda': 3.2372937902683456}. Best is trial 0 with value: 1.9887003370243408.\n",
            "[I 2025-07-06 06:15:33,773] Trial 4 finished with value: 2.0917987786841077 and parameters: {'n_estimators': 482, 'max_depth': 8, 'learning_rate': 0.14688360520643085, 'subsample': 0.630170260345608, 'colsample_bytree': 0.7611941567486263, 'reg_alpha': 0.29785840901564586, 'reg_lambda': 7.526221118034048}. Best is trial 0 with value: 1.9887003370243408.\n",
            "[I 2025-07-06 06:18:19,834] A new study created in memory with name: hour_12\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hour 11 - Best MAE: 1.9887\n",
            "Training model for hour 12...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-06 06:22:20,596] Trial 0 finished with value: 2.669803995708106 and parameters: {'n_estimators': 267, 'max_depth': 7, 'learning_rate': 0.15558332099177552, 'subsample': 0.7849014189220331, 'colsample_bytree': 0.8694735694633351, 'reg_alpha': 6.518389899672548, 'reg_lambda': 1.3697063697199614}. Best is trial 0 with value: 2.669803995708106.\n",
            "[I 2025-07-06 06:23:51,593] Trial 1 finished with value: 2.691546286172226 and parameters: {'n_estimators': 149, 'max_depth': 6, 'learning_rate': 0.19688835451475004, 'subsample': 0.6091279653038345, 'colsample_bytree': 0.7345572534444831, 'reg_alpha': 0.18775035207258514, 'reg_lambda': 6.531645385150081}. Best is trial 0 with value: 2.669803995708106.\n",
            "[I 2025-07-06 06:29:18,746] Trial 2 finished with value: 3.12916733788572 and parameters: {'n_estimators': 342, 'max_depth': 8, 'learning_rate': 0.0987372367120699, 'subsample': 0.8673218948960233, 'colsample_bytree': 0.6178938299166181, 'reg_alpha': 7.081730316328106, 'reg_lambda': 4.900843732449312}. Best is trial 0 with value: 2.669803995708106.\n",
            "[I 2025-07-06 06:31:29,890] Trial 3 finished with value: 2.737426085450276 and parameters: {'n_estimators': 261, 'max_depth': 5, 'learning_rate': 0.09064898469079902, 'subsample': 0.7059422475519646, 'colsample_bytree': 0.9294327602050625, 'reg_alpha': 5.155598110211047, 'reg_lambda': 4.1804537724750315}. Best is trial 0 with value: 2.669803995708106.\n",
            "[I 2025-07-06 06:37:29,622] Trial 4 finished with value: 2.639166843625264 and parameters: {'n_estimators': 412, 'max_depth': 7, 'learning_rate': 0.2118076730507036, 'subsample': 0.8882968273223437, 'colsample_bytree': 0.7409574636088438, 'reg_alpha': 2.7885246199471303, 'reg_lambda': 2.6946733815135695}. Best is trial 4 with value: 2.639166843625264.\n",
            "[I 2025-07-06 06:43:23,822] A new study created in memory with name: hour_13\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hour 12 - Best MAE: 2.6392\n",
            "Training model for hour 13...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-06 06:44:16,624] Trial 0 finished with value: 2.084970950062583 and parameters: {'n_estimators': 184, 'max_depth': 3, 'learning_rate': 0.195996752566241, 'subsample': 0.8892310001221211, 'colsample_bytree': 0.9636334480808656, 'reg_alpha': 3.4690385752021315, 'reg_lambda': 5.615009755360443}. Best is trial 0 with value: 2.084970950062583.\n",
            "[I 2025-07-06 06:45:46,779] Trial 1 finished with value: 2.0708983910533956 and parameters: {'n_estimators': 248, 'max_depth': 4, 'learning_rate': 0.13667366281470267, 'subsample': 0.8829824661547884, 'colsample_bytree': 0.9585475496236425, 'reg_alpha': 2.0535757283831915, 'reg_lambda': 8.639499189873439}. Best is trial 1 with value: 2.0708983910533956.\n",
            "[I 2025-07-06 06:50:17,482] Trial 2 finished with value: 2.1172860652655046 and parameters: {'n_estimators': 257, 'max_depth': 8, 'learning_rate': 0.15112742042327265, 'subsample': 0.6029452051430927, 'colsample_bytree': 0.895256496281422, 'reg_alpha': 7.258654185101637, 'reg_lambda': 0.6757187196352539}. Best is trial 1 with value: 2.0708983910533956.\n",
            "[I 2025-07-06 06:52:19,505] Trial 3 finished with value: 2.2338517852049034 and parameters: {'n_estimators': 193, 'max_depth': 6, 'learning_rate': 0.17436358738675325, 'subsample': 0.912196160854723, 'colsample_bytree': 0.6851082192645208, 'reg_alpha': 7.310816712050581, 'reg_lambda': 5.577973589633088}. Best is trial 1 with value: 2.0708983910533956.\n",
            "[I 2025-07-06 06:53:34,629] Trial 4 finished with value: 2.1434809958939742 and parameters: {'n_estimators': 104, 'max_depth': 6, 'learning_rate': 0.20204697887268547, 'subsample': 0.8321256277496044, 'colsample_bytree': 0.998000946987111, 'reg_alpha': 8.488916871992695, 'reg_lambda': 0.8228167130203712}. Best is trial 1 with value: 2.0708983910533956.\n",
            "[I 2025-07-06 06:55:05,475] A new study created in memory with name: hour_14\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hour 13 - Best MAE: 2.0709\n",
            "Training model for hour 14...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-06 06:57:07,073] Trial 0 finished with value: 1.6153838460038348 and parameters: {'n_estimators': 258, 'max_depth': 5, 'learning_rate': 0.2658949771684822, 'subsample': 0.7625057268690187, 'colsample_bytree': 0.7243125372914904, 'reg_alpha': 8.958582925133326, 'reg_lambda': 9.4173972111617}. Best is trial 0 with value: 1.6153838460038348.\n",
            "[I 2025-07-06 06:58:24,683] Trial 1 finished with value: 2.0395056815152937 and parameters: {'n_estimators': 282, 'max_depth': 3, 'learning_rate': 0.01967110027583882, 'subsample': 0.9785898467970215, 'colsample_bytree': 0.9032835039831323, 'reg_alpha': 9.499729930057102, 'reg_lambda': 9.755069282930899}. Best is trial 0 with value: 1.6153838460038348.\n",
            "[I 2025-07-06 07:00:11,685] Trial 2 finished with value: 1.4748321564048146 and parameters: {'n_estimators': 209, 'max_depth': 5, 'learning_rate': 0.21356104808604234, 'subsample': 0.8449192149966317, 'colsample_bytree': 0.9475466448848472, 'reg_alpha': 0.6935292674455269, 'reg_lambda': 7.760764025829892}. Best is trial 2 with value: 1.4748321564048146.\n",
            "[I 2025-07-06 07:01:53,976] Trial 3 finished with value: 1.7393409470091432 and parameters: {'n_estimators': 218, 'max_depth': 5, 'learning_rate': 0.07035542323717688, 'subsample': 0.6512131924452768, 'colsample_bytree': 0.7286230443469726, 'reg_alpha': 8.916560876861618, 'reg_lambda': 8.957301808739201}. Best is trial 2 with value: 1.4748321564048146.\n",
            "[I 2025-07-06 07:05:48,571] Trial 4 finished with value: 1.484906621945326 and parameters: {'n_estimators': 463, 'max_depth': 5, 'learning_rate': 0.10750410239337095, 'subsample': 0.7870102573501374, 'colsample_bytree': 0.9640037319241609, 'reg_alpha': 6.358719600129754, 'reg_lambda': 2.9038659832779476}. Best is trial 2 with value: 1.4748321564048146.\n",
            "[I 2025-07-06 07:07:30,271] A new study created in memory with name: hour_15\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hour 14 - Best MAE: 1.4748\n",
            "Training model for hour 15...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-06 07:14:22,390] Trial 0 finished with value: 1.3338220639648977 and parameters: {'n_estimators': 439, 'max_depth': 7, 'learning_rate': 0.19177091800754045, 'subsample': 0.6571442026904694, 'colsample_bytree': 0.8965920418968104, 'reg_alpha': 3.277409902331912, 'reg_lambda': 9.003463754435797}. Best is trial 0 with value: 1.3338220639648977.\n",
            "[I 2025-07-06 07:15:05,321] Trial 1 finished with value: 1.4984469084885323 and parameters: {'n_estimators': 144, 'max_depth': 3, 'learning_rate': 0.16450117189712438, 'subsample': 0.7672112822952922, 'colsample_bytree': 0.7585476513991395, 'reg_alpha': 6.305444989489367, 'reg_lambda': 4.453606289290347}. Best is trial 0 with value: 1.3338220639648977.\n",
            "[I 2025-07-06 07:16:04,686] Trial 2 finished with value: 1.3198251097722513 and parameters: {'n_estimators': 152, 'max_depth': 4, 'learning_rate': 0.23106723333488768, 'subsample': 0.9061370757493835, 'colsample_bytree': 0.8442036480994052, 'reg_alpha': 6.167533182560983, 'reg_lambda': 8.961134454680636}. Best is trial 2 with value: 1.3198251097722513.\n",
            "[I 2025-07-06 07:19:40,567] Trial 3 finished with value: 1.3025877742855347 and parameters: {'n_estimators': 232, 'max_depth': 7, 'learning_rate': 0.28156177152996764, 'subsample': 0.8083742832994057, 'colsample_bytree': 0.9408425489813192, 'reg_alpha': 8.333974077155645, 'reg_lambda': 0.5337401043787404}. Best is trial 3 with value: 1.3025877742855347.\n",
            "[I 2025-07-06 07:25:13,892] Trial 4 finished with value: 1.3198724091642378 and parameters: {'n_estimators': 266, 'max_depth': 8, 'learning_rate': 0.25981141498922045, 'subsample': 0.7638301171023562, 'colsample_bytree': 0.9073546376537224, 'reg_alpha': 3.810112495611192, 'reg_lambda': 4.390330428186319}. Best is trial 3 with value: 1.3025877742855347.\n",
            "[I 2025-07-06 07:28:55,078] A new study created in memory with name: hour_16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hour 15 - Best MAE: 1.3026\n",
            "Training model for hour 16...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-06 07:36:47,770] Trial 0 finished with value: 1.5796527361461907 and parameters: {'n_estimators': 408, 'max_depth': 8, 'learning_rate': 0.2983484128807289, 'subsample': 0.8774183313648494, 'colsample_bytree': 0.7985594716430385, 'reg_alpha': 1.6416289971493034, 'reg_lambda': 2.5191259633636944}. Best is trial 0 with value: 1.5796527361461907.\n",
            "[I 2025-07-06 07:37:25,036] Trial 1 finished with value: 1.4959200762180418 and parameters: {'n_estimators': 120, 'max_depth': 3, 'learning_rate': 0.17877787769881875, 'subsample': 0.9938768781771534, 'colsample_bytree': 0.9398144061606423, 'reg_alpha': 8.935623643985409, 'reg_lambda': 0.8977760274202519}. Best is trial 1 with value: 1.4959200762180418.\n",
            "[I 2025-07-06 07:42:36,367] Trial 2 finished with value: 1.5787687575590965 and parameters: {'n_estimators': 292, 'max_depth': 8, 'learning_rate': 0.23827332905193238, 'subsample': 0.8402333880702055, 'colsample_bytree': 0.7509765860345863, 'reg_alpha': 8.88660790563363, 'reg_lambda': 7.870357415956433}. Best is trial 1 with value: 1.4959200762180418.\n",
            "[I 2025-07-06 07:48:57,293] Trial 3 finished with value: 1.5608749129466681 and parameters: {'n_estimators': 350, 'max_depth': 8, 'learning_rate': 0.2929520742526238, 'subsample': 0.8859056031480048, 'colsample_bytree': 0.8034589404242614, 'reg_alpha': 0.6535090806972517, 'reg_lambda': 3.6310433060015215}. Best is trial 1 with value: 1.4959200762180418.\n",
            "[I 2025-07-06 07:49:57,735] Trial 4 finished with value: 1.5133371521281798 and parameters: {'n_estimators': 155, 'max_depth': 4, 'learning_rate': 0.1752900045616956, 'subsample': 0.606071927812681, 'colsample_bytree': 0.9411115537683079, 'reg_alpha': 8.616149670591152, 'reg_lambda': 9.524756397510822}. Best is trial 1 with value: 1.4959200762180418.\n",
            "[I 2025-07-06 07:50:34,325] A new study created in memory with name: hour_17\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hour 16 - Best MAE: 1.4959\n",
            "Training model for hour 17...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-06 07:53:24,867] Trial 0 finished with value: 1.5185805003758044 and parameters: {'n_estimators': 346, 'max_depth': 5, 'learning_rate': 0.21961176410046684, 'subsample': 0.6614526477308585, 'colsample_bytree': 0.8319716472351595, 'reg_alpha': 8.373273019229554, 'reg_lambda': 2.264825047899288}. Best is trial 0 with value: 1.5185805003758044.\n",
            "[I 2025-07-06 07:55:25,072] Trial 1 finished with value: 1.633737121958332 and parameters: {'n_estimators': 145, 'max_depth': 7, 'learning_rate': 0.2763846855610121, 'subsample': 0.9187863223849444, 'colsample_bytree': 0.6965717940259346, 'reg_alpha': 9.069443939064383, 'reg_lambda': 9.71211183246078}. Best is trial 0 with value: 1.5185805003758044.\n",
            "[I 2025-07-06 07:57:36,546] Trial 2 finished with value: 1.5199691115547322 and parameters: {'n_estimators': 491, 'max_depth': 3, 'learning_rate': 0.04408761544507741, 'subsample': 0.9182625570172688, 'colsample_bytree': 0.8457377845044998, 'reg_alpha': 4.178741679231222, 'reg_lambda': 5.8821575499911285}. Best is trial 0 with value: 1.5185805003758044.\n",
            "[I 2025-07-06 08:00:28,272] Trial 3 finished with value: 1.526595700685248 and parameters: {'n_estimators': 494, 'max_depth': 4, 'learning_rate': 0.09626372338754617, 'subsample': 0.7476394797467185, 'colsample_bytree': 0.6926923268884754, 'reg_alpha': 7.714853824960967, 'reg_lambda': 7.6464181975025065}. Best is trial 0 with value: 1.5185805003758044.\n",
            "[I 2025-07-06 08:08:50,959] Trial 4 finished with value: 1.607475182005513 and parameters: {'n_estimators': 447, 'max_depth': 8, 'learning_rate': 0.2828983934502515, 'subsample': 0.8761497790477353, 'colsample_bytree': 0.6388865162537731, 'reg_alpha': 4.724805025961611, 'reg_lambda': 2.0150073041432752}. Best is trial 0 with value: 1.5185805003758044.\n",
            "[I 2025-07-06 08:11:46,984] A new study created in memory with name: hour_18\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hour 17 - Best MAE: 1.5186\n",
            "Training model for hour 18...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-06 08:19:26,959] Trial 0 finished with value: 1.5333914485689817 and parameters: {'n_estimators': 387, 'max_depth': 8, 'learning_rate': 0.2027453330356101, 'subsample': 0.9763216022509652, 'colsample_bytree': 0.9446931724325209, 'reg_alpha': 9.313175242685517, 'reg_lambda': 0.07517485394738961}. Best is trial 0 with value: 1.5333914485689817.\n",
            "[I 2025-07-06 08:20:30,047] Trial 1 finished with value: 1.5752270424401704 and parameters: {'n_estimators': 171, 'max_depth': 4, 'learning_rate': 0.14068659579216183, 'subsample': 0.7120928150607289, 'colsample_bytree': 0.741947959232676, 'reg_alpha': 8.198468036047636, 'reg_lambda': 9.686131494264787}. Best is trial 0 with value: 1.5333914485689817.\n",
            "[I 2025-07-06 08:25:36,672] Trial 2 finished with value: 1.522773166484286 and parameters: {'n_estimators': 447, 'max_depth': 6, 'learning_rate': 0.19409587661752098, 'subsample': 0.6415177155001915, 'colsample_bytree': 0.9894420049767357, 'reg_alpha': 9.447259310673834, 'reg_lambda': 8.58178157981835}. Best is trial 2 with value: 1.522773166484286.\n",
            "[I 2025-07-06 08:28:28,665] Trial 3 finished with value: 1.4906693063906538 and parameters: {'n_estimators': 346, 'max_depth': 5, 'learning_rate': 0.21643380497671372, 'subsample': 0.9621632897287139, 'colsample_bytree': 0.9942296018721296, 'reg_alpha': 6.911415420080585, 'reg_lambda': 1.6440009097426533}. Best is trial 3 with value: 1.4906693063906538.\n",
            "[I 2025-07-06 08:29:59,835] Trial 4 finished with value: 1.54040124286379 and parameters: {'n_estimators': 183, 'max_depth': 5, 'learning_rate': 0.08396654413310943, 'subsample': 0.7088853880919715, 'colsample_bytree': 0.8866359699990285, 'reg_alpha': 4.716839847368922, 'reg_lambda': 2.439568610204641}. Best is trial 3 with value: 1.4906693063906538.\n",
            "[I 2025-07-06 08:32:56,395] A new study created in memory with name: hour_19\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hour 18 - Best MAE: 1.4907\n",
            "Training model for hour 19...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-06 08:33:48,075] Trial 0 finished with value: 1.5153418231096236 and parameters: {'n_estimators': 179, 'max_depth': 3, 'learning_rate': 0.11854546814035578, 'subsample': 0.9800795502337607, 'colsample_bytree': 0.9064892939186143, 'reg_alpha': 1.5314585576439694, 'reg_lambda': 1.310808255712167}. Best is trial 0 with value: 1.5153418231096236.\n",
            "[I 2025-07-06 08:36:02,917] Trial 1 finished with value: 1.5120648079676007 and parameters: {'n_estimators': 490, 'max_depth': 3, 'learning_rate': 0.08741405756888979, 'subsample': 0.7354437425623163, 'colsample_bytree': 0.8982946324483557, 'reg_alpha': 8.958896525350834, 'reg_lambda': 6.995045519535005}. Best is trial 1 with value: 1.5120648079676007.\n",
            "[I 2025-07-06 08:41:58,893] Trial 2 finished with value: 1.5065162611225043 and parameters: {'n_estimators': 287, 'max_depth': 8, 'learning_rate': 0.10107116245924101, 'subsample': 0.8285490343555721, 'colsample_bytree': 0.9962972597196438, 'reg_alpha': 5.832932036178206, 'reg_lambda': 7.464290349772916}. Best is trial 2 with value: 1.5065162611225043.\n",
            "[I 2025-07-06 08:46:11,868] Trial 3 finished with value: 1.5285497999408635 and parameters: {'n_estimators': 282, 'max_depth': 7, 'learning_rate': 0.22005910149496347, 'subsample': 0.7490415336003329, 'colsample_bytree': 0.843052400601503, 'reg_alpha': 4.261776586652719, 'reg_lambda': 4.643951836875458}. Best is trial 2 with value: 1.5065162611225043.\n",
            "[I 2025-07-06 08:48:41,815] Trial 4 finished with value: 1.4849194060819682 and parameters: {'n_estimators': 414, 'max_depth': 4, 'learning_rate': 0.1308296338076368, 'subsample': 0.9309187013960016, 'colsample_bytree': 0.9716597074258569, 'reg_alpha': 5.529377584327443, 'reg_lambda': 6.82431711394264}. Best is trial 4 with value: 1.4849194060819682.\n",
            "[I 2025-07-06 08:51:12,989] A new study created in memory with name: hour_20\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hour 19 - Best MAE: 1.4849\n",
            "Training model for hour 20...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-06 08:56:13,514] Trial 0 finished with value: 1.5880910813919296 and parameters: {'n_estimators': 466, 'max_depth': 6, 'learning_rate': 0.2286133791427188, 'subsample': 0.8437295753394829, 'colsample_bytree': 0.7812214863023711, 'reg_alpha': 4.511759414986952, 'reg_lambda': 7.332138311814312}. Best is trial 0 with value: 1.5880910813919296.\n",
            "[I 2025-07-06 08:57:30,629] Trial 1 finished with value: 1.581454320991006 and parameters: {'n_estimators': 155, 'max_depth': 5, 'learning_rate': 0.28362657017671705, 'subsample': 0.818539416620677, 'colsample_bytree': 0.9211095389399587, 'reg_alpha': 2.530400526909483, 'reg_lambda': 6.086378692753491}. Best is trial 1 with value: 1.581454320991006.\n",
            "[I 2025-07-06 09:00:19,515] Trial 2 finished with value: 1.5794868440494774 and parameters: {'n_estimators': 147, 'max_depth': 8, 'learning_rate': 0.25418051872210345, 'subsample': 0.9644880030899429, 'colsample_bytree': 0.8130460479202103, 'reg_alpha': 7.935351762098379, 'reg_lambda': 4.2215518121820645}. Best is trial 2 with value: 1.5794868440494774.\n",
            "[I 2025-07-06 09:03:53,527] Trial 3 finished with value: 1.5728638244479716 and parameters: {'n_estimators': 259, 'max_depth': 7, 'learning_rate': 0.10754684295045963, 'subsample': 0.6470338009263049, 'colsample_bytree': 0.9035808521040187, 'reg_alpha': 9.81763683707291, 'reg_lambda': 5.08206031286476}. Best is trial 3 with value: 1.5728638244479716.\n",
            "[I 2025-07-06 09:05:43,666] Trial 4 finished with value: 1.5381615669959547 and parameters: {'n_estimators': 228, 'max_depth': 5, 'learning_rate': 0.12292797894483691, 'subsample': 0.961146252686792, 'colsample_bytree': 0.8534775923519052, 'reg_alpha': 7.47106549217582, 'reg_lambda': 2.204291302798113}. Best is trial 4 with value: 1.5381615669959547.\n",
            "[I 2025-07-06 09:07:32,253] A new study created in memory with name: hour_21\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hour 20 - Best MAE: 1.5382\n",
            "Training model for hour 21...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-06 09:09:07,258] Trial 0 finished with value: 1.5198700984858802 and parameters: {'n_estimators': 271, 'max_depth': 4, 'learning_rate': 0.14826280988065593, 'subsample': 0.8041359535575802, 'colsample_bytree': 0.7315408164681018, 'reg_alpha': 5.080645279128086, 'reg_lambda': 2.6533191076222584}. Best is trial 0 with value: 1.5198700984858802.\n",
            "[I 2025-07-06 09:10:26,201] Trial 1 finished with value: 1.7071099408193373 and parameters: {'n_estimators': 127, 'max_depth': 6, 'learning_rate': 0.0415014917136121, 'subsample': 0.8589371148616045, 'colsample_bytree': 0.7206095980420903, 'reg_alpha': 6.797010159616393, 'reg_lambda': 4.492974984109677}. Best is trial 0 with value: 1.5198700984858802.\n",
            "[I 2025-07-06 09:11:18,574] Trial 2 finished with value: 1.4716091966732492 and parameters: {'n_estimators': 182, 'max_depth': 3, 'learning_rate': 0.15770081503736796, 'subsample': 0.7117033178726728, 'colsample_bytree': 0.833775635552973, 'reg_alpha': 4.137425902886976, 'reg_lambda': 5.677673846413161}. Best is trial 2 with value: 1.4716091966732492.\n",
            "[I 2025-07-06 09:14:38,866] Trial 3 finished with value: 1.5354280561143443 and parameters: {'n_estimators': 189, 'max_depth': 8, 'learning_rate': 0.23073664199685243, 'subsample': 0.6084536905003763, 'colsample_bytree': 0.9482675157784499, 'reg_alpha': 8.815247220339472, 'reg_lambda': 9.844723081779394}. Best is trial 2 with value: 1.4716091966732492.\n",
            "[I 2025-07-06 09:15:44,737] Trial 4 finished with value: 1.4975850283485346 and parameters: {'n_estimators': 238, 'max_depth': 3, 'learning_rate': 0.11842815623989285, 'subsample': 0.6814133943415406, 'colsample_bytree': 0.8800362896289183, 'reg_alpha': 0.7451114944146873, 'reg_lambda': 9.037075519217234}. Best is trial 2 with value: 1.4716091966732492.\n",
            "[I 2025-07-06 09:16:36,491] A new study created in memory with name: hour_22\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hour 21 - Best MAE: 1.4716\n",
            "Training model for hour 22...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-06 09:19:04,551] Trial 0 finished with value: 1.5241588267130548 and parameters: {'n_estimators': 263, 'max_depth': 6, 'learning_rate': 0.1471661345998365, 'subsample': 0.7352747278502849, 'colsample_bytree': 0.8255717757568461, 'reg_alpha': 0.797781669826483, 'reg_lambda': 0.6045233113682624}. Best is trial 0 with value: 1.5241588267130548.\n",
            "[I 2025-07-06 09:21:19,483] Trial 1 finished with value: 1.5496845871721918 and parameters: {'n_estimators': 487, 'max_depth': 3, 'learning_rate': 0.07578165804488493, 'subsample': 0.6056779676229452, 'colsample_bytree': 0.948080559103299, 'reg_alpha': 2.230907187483302, 'reg_lambda': 9.979245238081257}. Best is trial 0 with value: 1.5241588267130548.\n",
            "[I 2025-07-06 09:22:43,535] Trial 2 finished with value: 1.5873822963634359 and parameters: {'n_estimators': 242, 'max_depth': 4, 'learning_rate': 0.22340935016815855, 'subsample': 0.8489333909514478, 'colsample_bytree': 0.6900251084378249, 'reg_alpha': 0.6860371678579736, 'reg_lambda': 9.32289267730662}. Best is trial 0 with value: 1.5241588267130548.\n",
            "[I 2025-07-06 09:27:01,941] Trial 3 finished with value: 1.5179787870065706 and parameters: {'n_estimators': 385, 'max_depth': 6, 'learning_rate': 0.10695082617997835, 'subsample': 0.7407159780365131, 'colsample_bytree': 0.908403478851171, 'reg_alpha': 6.741942081052633, 'reg_lambda': 2.991433088382057}. Best is trial 3 with value: 1.5179787870065706.\n",
            "[I 2025-07-06 09:30:46,239] Trial 4 finished with value: 1.5424782996626265 and parameters: {'n_estimators': 197, 'max_depth': 8, 'learning_rate': 0.10173176737918481, 'subsample': 0.669727650173832, 'colsample_bytree': 0.9721274454344524, 'reg_alpha': 1.784708998694575, 'reg_lambda': 5.364909158769645}. Best is trial 3 with value: 1.5179787870065706.\n",
            "[I 2025-07-06 09:35:02,131] A new study created in memory with name: hour_23\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hour 22 - Best MAE: 1.5180\n",
            "Training model for hour 23...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-06 09:37:59,359] Trial 0 finished with value: 1.7838171524991067 and parameters: {'n_estimators': 245, 'max_depth': 7, 'learning_rate': 0.018701346172571173, 'subsample': 0.6672661791840856, 'colsample_bytree': 0.7190484348019962, 'reg_alpha': 2.5803089084621433, 'reg_lambda': 1.256435748822521}. Best is trial 0 with value: 1.7838171524991067.\n",
            "[I 2025-07-06 09:38:38,997] Trial 1 finished with value: 2.0675060256050237 and parameters: {'n_estimators': 130, 'max_depth': 3, 'learning_rate': 0.01557468949439248, 'subsample': 0.8572885542052351, 'colsample_bytree': 0.843009368699337, 'reg_alpha': 5.401904447703317, 'reg_lambda': 4.335032476360563}. Best is trial 0 with value: 1.7838171524991067.\n",
            "[I 2025-07-06 09:39:50,332] Trial 2 finished with value: 1.600730108529156 and parameters: {'n_estimators': 264, 'max_depth': 3, 'learning_rate': 0.1728474791070572, 'subsample': 0.7721216519897961, 'colsample_bytree': 0.6529491111105302, 'reg_alpha': 3.001700943224904, 'reg_lambda': 3.6672173364407143}. Best is trial 2 with value: 1.600730108529156.\n",
            "[I 2025-07-06 09:41:48,554] Trial 3 finished with value: 1.6005581236832034 and parameters: {'n_estimators': 436, 'max_depth': 3, 'learning_rate': 0.03563490530168141, 'subsample': 0.7289000233237961, 'colsample_bytree': 0.8790997027504182, 'reg_alpha': 5.922350499361309, 'reg_lambda': 5.4120135619376235}. Best is trial 3 with value: 1.6005581236832034.\n",
            "[I 2025-07-06 09:43:04,052] Trial 4 finished with value: 1.6497786839044946 and parameters: {'n_estimators': 203, 'max_depth': 4, 'learning_rate': 0.04282981057074337, 'subsample': 0.7458755828796759, 'colsample_bytree': 0.9259607686253152, 'reg_alpha': 7.848790634975241, 'reg_lambda': 5.310370040982448}. Best is trial 3 with value: 1.6005581236832034.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hour 23 - Best MAE: 1.6006\n",
            "Training completed. 24 models trained.\n",
            "Preparing test data...\n",
            "Found 116 NaN values in test data (0.00%)\n",
            "Applied fitted imputer to test data\n",
            "NaN values after imputation: 0\n",
            "Test data shape: (33877, 119)\n",
            "Making predictions...\n",
            "Predictions shape: (33877, 123)\n",
            "True values shape: (33877, 123)\n",
            "\n",
            "Evaluation Results:\n",
            "==================================================\n",
            "first_week: MAE = 2.2263\n",
            "first_2_weeks: MAE = 2.2263\n",
            "first_month: MAE = 3.0495\n",
            "first_3_months: MAE = 1.9203\n",
            "entire_period: MAE = 1.7875\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "import optuna\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def kelvin_to_fahrenheit(temp_k):\n",
        "    \"\"\"Convert temperature from Kelvin to Fahrenheit\"\"\"\n",
        "    return (temp_k - 273.15) * 9/5 + 32\n",
        "\n",
        "def preprocess_temperatures(data_matrix, metadata_dict, data_name=\"data\"):\n",
        "    \"\"\"\n",
        "    Preprocess temperature data by converting Kelvin to Fahrenheit\n",
        "    \n",
        "    Args:\n",
        "        data_matrix: numpy array of observation data\n",
        "        metadata_dict: dictionary containing observation_ids mapping\n",
        "        data_name: string name for logging purposes\n",
        "\n",
        "    Returns:\n",
        "        data_matrix: preprocessed data matrix (modified in-place)\n",
        "        temp_conversion_info: dictionary with conversion statistics\n",
        "    \"\"\"\n",
        "    \n",
        "    print(f\"\\n=== Temperature Preprocessing for {data_name} ===\")\n",
        "    \n",
        "    # Find temperature-related observation IDs\n",
        "    temp_sensor_ids = []\n",
        "    temp_setpoint_ids = []\n",
        "    \n",
        "    for obs_name, obs_idx in metadata_dict.items():\n",
        "        if any(temp_keyword in obs_name.lower() for temp_keyword in [\n",
        "            'temperature_sensor', 'temperature_setpoint', \n",
        "            'air_temperature', 'mixed_air_temperature',\n",
        "            'supply_air_temperature', 'return_air_temperature',\n",
        "            'discharge_air_temperature', 'outside_air_temperature'\n",
        "        ]):\n",
        "            if 'sensor' in obs_name:\n",
        "                temp_sensor_ids.append((obs_name, obs_idx))\n",
        "            elif 'setpoint' in obs_name:\n",
        "                temp_setpoint_ids.append((obs_name, obs_idx))\n",
        "            else:\n",
        "                # Default to sensor if unclear\n",
        "                temp_sensor_ids.append((obs_name, obs_idx))\n",
        "    \n",
        "    print(f\"Found {len(temp_sensor_ids)} temperature sensors\")\n",
        "    print(f\"Found {len(temp_setpoint_ids)} temperature setpoints\")\n",
        "    \n",
        "    conversion_info = {\n",
        "        'sensors_converted': 0,\n",
        "        'setpoints_converted': 0,\n",
        "        'total_values_converted': 0,\n",
        "        'sensor_details': [],\n",
        "        'setpoint_details': []\n",
        "    }\n",
        "    \n",
        "    # Process temperature sensors\n",
        "    for obs_name, obs_idx in temp_sensor_ids:\n",
        "        temp_values = data_matrix[:, obs_idx]\n",
        "        \n",
        "        # Find values that might be in Kelvin (> 273)\n",
        "        kelvin_mask = temp_values > 273\n",
        "        kelvin_count = np.sum(kelvin_mask)\n",
        "        \n",
        "        if kelvin_count > 0:\n",
        "            print(f\"  Converting {kelvin_count}/{len(temp_values)} values in {obs_name}\")\n",
        "            print(f\"    Before: min={temp_values[kelvin_mask].min():.2f}, max={temp_values[kelvin_mask].max():.2f}\")\n",
        "            \n",
        "            # Convert Kelvin to Fahrenheit\n",
        "            data_matrix[kelvin_mask, obs_idx] = kelvin_to_fahrenheit(temp_values[kelvin_mask])\n",
        "            \n",
        "            print(f\"    After:  min={data_matrix[kelvin_mask, obs_idx].min():.2f}, max={data_matrix[kelvin_mask, obs_idx].max():.2f}\")\n",
        "            \n",
        "            conversion_info['sensors_converted'] += 1\n",
        "            conversion_info['total_values_converted'] += kelvin_count\n",
        "            conversion_info['sensor_details'].append({\n",
        "                'name': obs_name,\n",
        "                'index': obs_idx,\n",
        "                'values_converted': kelvin_count,\n",
        "                'total_values': len(temp_values)\n",
        "            })\n",
        "    \n",
        "    # Process temperature setpoints\n",
        "    for obs_name, obs_idx in temp_setpoint_ids:\n",
        "        temp_values = data_matrix[:, obs_idx]\n",
        "        \n",
        "        # Find values that might be in Kelvin (> 273)\n",
        "        kelvin_mask = temp_values > 273\n",
        "        kelvin_count = np.sum(kelvin_mask)\n",
        "        \n",
        "        if kelvin_count > 0:\n",
        "            print(f\"  Converting {kelvin_count}/{len(temp_values)} values in {obs_name}\")\n",
        "            print(f\"    Before: min={temp_values[kelvin_mask].min():.2f}, max={temp_values[kelvin_mask].max():.2f}\")\n",
        "            \n",
        "            # Convert Kelvin to Fahrenheit\n",
        "            data_matrix[kelvin_mask, obs_idx] = kelvin_to_fahrenheit(temp_values[kelvin_mask])\n",
        "            \n",
        "            print(f\"    After:  min={data_matrix[kelvin_mask, obs_idx].min():.2f}, max={data_matrix[kelvin_mask, obs_idx].max():.2f}\")\n",
        "            \n",
        "            conversion_info['setpoints_converted'] += 1\n",
        "            conversion_info['total_values_converted'] += kelvin_count\n",
        "            conversion_info['setpoint_details'].append({\n",
        "                'name': obs_name,\n",
        "                'index': obs_idx,\n",
        "                'values_converted': kelvin_count,\n",
        "                'total_values': len(temp_values)\n",
        "            })\n",
        "    \n",
        "    print(f\"\\nConversion Summary for {data_name}:\")\n",
        "    print(f\"  Temperature sensors converted: {conversion_info['sensors_converted']}\")\n",
        "    print(f\"  Temperature setpoints converted: {conversion_info['setpoints_converted']}\")\n",
        "    print(f\"  Total values converted: {conversion_info['total_values_converted']}\")\n",
        "    \n",
        "    return data_matrix, conversion_info\n",
        "\n",
        "def preprocess_temp_data_array(temp_data_array, temp_data_ids, data_name=\"temperature data\"):\n",
        "    \"\"\"\n",
        "    Preprocess temperature data array (for validation temperature data)\n",
        "    \n",
        "    Args:\n",
        "        temp_data_array: numpy array of temperature data\n",
        "        temp_data_ids: dictionary mapping temperature sensor names to column indices\n",
        "        data_name: string name for logging purposes\n",
        "\n",
        "    Returns:\n",
        "        temp_data_array: preprocessed temperature data (modified in-place)\n",
        "        conversion_info: dictionary with conversion statistics\n",
        "    \"\"\"\n",
        "    \n",
        "    print(f\"\\n=== Temperature Preprocessing for {data_name} ===\")\n",
        "    \n",
        "    conversion_info = {\n",
        "        'sensors_converted': 0,\n",
        "        'total_values_converted': 0,\n",
        "        'sensor_details': []\n",
        "    }\n",
        "    \n",
        "    for sensor_name, col_idx in temp_data_ids.items():\n",
        "        temp_values = temp_data_array[:, col_idx]\n",
        "        \n",
        "        # Find values that might be in Kelvin (> 273)\n",
        "        kelvin_mask = temp_values > 273\n",
        "        kelvin_count = np.sum(kelvin_mask)\n",
        "        \n",
        "        if kelvin_count > 0:\n",
        "            print(f\"  Converting {kelvin_count}/{len(temp_values)} values in {sensor_name}\")\n",
        "            print(f\"    Before: min={temp_values[kelvin_mask].min():.2f}, max={temp_values[kelvin_mask].max():.2f}\")\n",
        "            \n",
        "            # Convert Kelvin to Fahrenheit\n",
        "            temp_data_array[kelvin_mask, col_idx] = kelvin_to_fahrenheit(temp_values[kelvin_mask])\n",
        "            \n",
        "            print(f\"    After:  min={temp_data_array[kelvin_mask, col_idx].min():.2f}, max={temp_data_array[kelvin_mask, col_idx].max():.2f}\")\n",
        "            \n",
        "            conversion_info['sensors_converted'] += 1\n",
        "            conversion_info['total_values_converted'] += kelvin_count\n",
        "            conversion_info['sensor_details'].append({\n",
        "                'name': sensor_name,\n",
        "                'index': col_idx,\n",
        "                'values_converted': kelvin_count,\n",
        "                'total_values': len(temp_values)\n",
        "            })\n",
        "    \n",
        "    print(f\"\\nConversion Summary for {data_name}:\")\n",
        "    print(f\"  Temperature sensors converted: {conversion_info['sensors_converted']}\")\n",
        "    print(f\"  Total values converted: {conversion_info['total_values_converted']}\")\n",
        "    \n",
        "    return temp_data_array, conversion_info\n",
        "\n",
        "def remove_zero_temperature_readings(obs_matrix, temp_data_matrix, exog_data_matrix, \n",
        "                                   timestamps_train, timestamps_val, metadata_obs_ids, \n",
        "                                   temp_data_ids, exog_data_ids):\n",
        "    \"\"\"\n",
        "    Remove rows where temperature sensors have zero values from both training and validation sets\n",
        "    \n",
        "    Args:\n",
        "        obs_matrix: training observation matrix\n",
        "        temp_data_matrix: validation temperature data matrix  \n",
        "        exog_data_matrix: validation exogenous data matrix\n",
        "        timestamps_train: training timestamps\n",
        "        timestamps_val: validation timestamps\n",
        "        metadata_obs_ids: training observation IDs mapping\n",
        "        temp_data_ids: validation temperature IDs mapping\n",
        "        exog_data_ids: validation exogenous IDs mapping\n",
        "\n",
        "    Returns:\n",
        "        Cleaned datasets with zero temperature readings removed\n",
        "    \"\"\"\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"REMOVING ZERO TEMPERATURE READINGS\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # 1. Clean training data\n",
        "    print(\"\\nCleaning training data...\")\n",
        "    \n",
        "    # Find temperature sensor columns in training data\n",
        "    train_temp_indices = [v for k, v in metadata_obs_ids.items() \n",
        "                         if \"zone_air_temperature_sensor\" in k]\n",
        "    \n",
        "    # Get temperature data from training matrix\n",
        "    train_temp_data = obs_matrix[:, train_temp_indices]\n",
        "    \n",
        "    # Find rows where ANY temperature sensor has zero values\n",
        "    zero_mask_train = np.any(train_temp_data == 0, axis=1)\n",
        "    valid_mask_train = ~zero_mask_train\n",
        "    \n",
        "    print(f\"  Original training data: {len(obs_matrix)} rows\")\n",
        "    print(f\"  Rows with zero temperatures: {np.sum(zero_mask_train)}\")\n",
        "    print(f\"  Rows to keep: {np.sum(valid_mask_train)}\")\n",
        "    print(f\"  Percentage kept: {np.sum(valid_mask_train)/len(obs_matrix)*100:.1f}%\")\n",
        "    \n",
        "    # Apply mask to training data\n",
        "    obs_matrix_clean = obs_matrix[valid_mask_train]\n",
        "    timestamps_train_clean = [timestamps_train[i] for i in range(len(timestamps_train)) if valid_mask_train[i]]\n",
        "    \n",
        "    # 2. Clean validation data\n",
        "    print(\"\\nCleaning validation data...\")\n",
        "    \n",
        "    # Find rows where ANY temperature sensor has zero values in validation\n",
        "    zero_mask_val = np.any(temp_data_matrix == 0, axis=1)\n",
        "    valid_mask_val = ~zero_mask_val\n",
        "    \n",
        "    print(f\"  Original validation data: {len(temp_data_matrix)} rows\")\n",
        "    print(f\"  Rows with zero temperatures: {np.sum(zero_mask_val)}\")\n",
        "    print(f\"  Rows to keep: {np.sum(valid_mask_val)}\")\n",
        "    print(f\"  Percentage kept: {np.sum(valid_mask_val)/len(temp_data_matrix)*100:.1f}%\")\n",
        "    \n",
        "    # Apply mask to validation data\n",
        "    temp_data_clean = temp_data_matrix[valid_mask_val]\n",
        "    exog_data_clean = exog_data_matrix[valid_mask_val]\n",
        "    timestamps_val_clean = [timestamps_val[i] for i in range(len(timestamps_val)) if valid_mask_val[i]]\n",
        "    \n",
        "    print(f\"\\nData cleaning summary:\")\n",
        "    print(f\"  Training: {len(obs_matrix)} -> {len(obs_matrix_clean)} rows\")\n",
        "    print(f\"  Validation: {len(temp_data_matrix)} -> {len(temp_data_clean)} rows\")\n",
        "    \n",
        "    return (obs_matrix_clean, temp_data_clean, exog_data_clean, \n",
        "            timestamps_train_clean, timestamps_val_clean)\n",
        "\n",
        "# ===== MAIN PREPROCESSING STEP =====\n",
        "print(\"Starting temperature preprocessing...\")\n",
        "\n",
        "# First, extract arrays from NpzFile objects to make them modifiable\n",
        "print(\"Extracting arrays from NpzFile objects...\")\n",
        "\n",
        "# Extract training observation matrix (make it modifiable)\n",
        "train_obs_matrix = np.array(data['observation_value_matrix'])\n",
        "print(f\"Training observation matrix shape: {train_obs_matrix.shape}\")\n",
        "\n",
        "# Extract validation exogenous data (make it modifiable) \n",
        "val_exog_matrix = np.array(exogenous_observation_data)\n",
        "print(f\"Validation exogenous matrix shape: {val_exog_matrix.shape}\")\n",
        "\n",
        "# Extract validation temperature data (make it modifiable)\n",
        "val_temp_matrix = np.array(temp_data)\n",
        "print(f\"Validation temperature matrix shape: {val_temp_matrix.shape}\")\n",
        "\n",
        "# 1. Preprocess training data (observation_value_matrix)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PREPROCESSING TRAINING DATA\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "train_obs_matrix, train_conversion_info = preprocess_temperatures(\n",
        "    train_obs_matrix, \n",
        "    metadata['observation_ids'], \n",
        "    \"training data\"\n",
        ")\n",
        "\n",
        "# 2. Preprocess validation exogenous data\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PREPROCESSING VALIDATION EXOGENOUS DATA\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "val_exog_matrix, val_exog_conversion_info = preprocess_temperatures(\n",
        "    val_exog_matrix, \n",
        "    exogenous_observation_data_ids, \n",
        "    \"validation exogenous data\"\n",
        ")\n",
        "\n",
        "# 3. Preprocess validation temperature data (targets)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PREPROCESSING VALIDATION TEMPERATURE DATA (TARGETS)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "val_temp_matrix, val_temp_conversion_info = preprocess_temp_data_array(\n",
        "    val_temp_matrix, \n",
        "    temp_data_ids, \n",
        "    \"validation temperature targets\"\n",
        ")\n",
        "\n",
        "# 4. Remove zero temperature readings from both training and validation\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"REMOVING ZERO TEMPERATURE READINGS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Remove rows with zero temperature readings\n",
        "(train_obs_matrix_clean, val_temp_matrix_clean, val_exog_matrix_clean, \n",
        " timestamps_train_clean, timestamps_val_clean) = remove_zero_temperature_readings(\n",
        "    train_obs_matrix, val_temp_matrix, val_exog_matrix,\n",
        "    metadata[\"observation_timestamps\"], metadata_val[\"observation_timestamps\"],\n",
        "    metadata['observation_ids'], temp_data_ids, exogenous_observation_data_ids\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TEMPERATURE PREPROCESSING COMPLETED\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Print overall summary\n",
        "total_converted = (train_conversion_info['total_values_converted'] + \n",
        "                  val_exog_conversion_info['total_values_converted'] + \n",
        "                  val_temp_conversion_info['total_values_converted'])\n",
        "\n",
        "print(f\"\\nOVERALL CONVERSION SUMMARY:\")\n",
        "print(f\"  Training data: {train_conversion_info['total_values_converted']} values converted\")\n",
        "print(f\"  Validation exogenous: {val_exog_conversion_info['total_values_converted']} values converted\")\n",
        "print(f\"  Validation targets: {val_temp_conversion_info['total_values_converted']} values converted\")\n",
        "print(f\"  TOTAL: {total_converted} temperature values converted from Kelvin to Fahrenheit\")\n",
        "\n",
        "print(f\"\\nOVERALL ZERO REMOVAL SUMMARY:\")\n",
        "print(f\"  Training data: {len(train_obs_matrix)} -> {len(train_obs_matrix_clean)} rows\")\n",
        "print(f\"  Validation data: {len(val_temp_matrix)} -> {len(val_temp_matrix_clean)} rows\")\n",
        "\n",
        "# Update the global variables to use the cleaned, preprocessed data\n",
        "print(\"\\nUpdating global variables with cleaned and preprocessed data...\")\n",
        "exogenous_observation_data = val_exog_matrix_clean\n",
        "temp_data = val_temp_matrix_clean\n",
        "\n",
        "print(\"Preprocessing complete! Now starting model training with Grouped PCA...\")\n",
        "\n",
        "# ===== MODEL WITH GROUPED PCA =====\n",
        "\n",
        "class SmartBuildingsPredictor:\n",
        "    def __init__(self, use_gpu=True, components_per_group=15):\n",
        "        self.use_gpu = use_gpu\n",
        "        self.components_per_group = components_per_group\n",
        "        self.models = {}  # Will store 24 hourly models\n",
        "        self.scalers = {}  # Will store scalers for each hour\n",
        "        self.group_pcas = {}  # Will store PCA transformers for each group\n",
        "        self.imputer = None  # Will store imputer for NaN handling\n",
        "        self.feature_groups = {}  # Will store feature group definitions\n",
        "        self.exog_feature_names = None  # Will store original exogenous feature names\n",
        "        self.feature_columns = None\n",
        "        self.temp_columns = None\n",
        "        \n",
        "    def interpolate_zeros(self, data):\n",
        "        \"\"\"Interpolate zero values in training data\"\"\"\n",
        "        data_df = pd.DataFrame(data)\n",
        "        # Replace zeros with NaN for interpolation\n",
        "        data_df = data_df.replace(0, np.nan)\n",
        "        # Forward fill then backward fill\n",
        "        data_df = data_df.fillna(method='ffill').fillna(method='bfill')\n",
        "        # If still NaN, fill with column mean\n",
        "        data_df = data_df.fillna(data_df.mean())\n",
        "        return data_df.values\n",
        "    \n",
        "    def handle_nan_values(self, exog_data, is_training=True):\n",
        "        \"\"\"Handle NaN values in exogenous data\"\"\"\n",
        "        nan_count = np.isnan(exog_data).sum()\n",
        "        \n",
        "        if is_training:\n",
        "            # Always fit imputer on training data (even if no NaN values)\n",
        "            # This ensures imputer is available for test data that might have NaN values\n",
        "            self.imputer = SimpleImputer(strategy='mean')\n",
        "            exog_data_clean = self.imputer.fit_transform(exog_data)\n",
        "            print(f\"Fitted imputer on training data (found {nan_count} NaN values, {nan_count/exog_data.size*100:.2f}%)\")\n",
        "        else:\n",
        "            # Use fitted imputer on test data\n",
        "            if self.imputer is None:\n",
        "                raise ValueError(\"Imputer not fitted yet. Train model first.\")\n",
        "            print(f\"Found {nan_count} NaN values in test data ({nan_count/exog_data.size*100:.2f}%)\")\n",
        "            exog_data_clean = self.imputer.transform(exog_data)\n",
        "            print(\"Applied fitted imputer to test data\")\n",
        "        \n",
        "        nan_count_after = np.isnan(exog_data_clean).sum()\n",
        "        print(f\"NaN values after imputation: {nan_count_after}\")\n",
        "        return exog_data_clean\n",
        "    \n",
        "    def create_temporal_features(self, timestamps):\n",
        "        \"\"\"Create temporal dummy features\"\"\"\n",
        "        features = []\n",
        "        \n",
        "        for ts in timestamps:\n",
        "            # Handle both pandas Timestamp and Unix timestamp\n",
        "            if hasattr(ts, 'hour'):  # pandas Timestamp\n",
        "                dt = ts\n",
        "            else:  # Unix timestamp\n",
        "                dt = datetime.fromtimestamp(ts)\n",
        "            \n",
        "            # Hour of day (0-23)\n",
        "            hour = dt.hour\n",
        "            \n",
        "            # Time of day categories\n",
        "            if 6 <= hour < 12:\n",
        "                time_of_day = [1, 0, 0, 0]  # morning\n",
        "            elif 12 <= hour < 18:\n",
        "                time_of_day = [0, 1, 0, 0]  # day\n",
        "            elif 18 <= hour < 22:\n",
        "                time_of_day = [0, 0, 1, 0]  # evening\n",
        "            else:\n",
        "                time_of_day = [0, 0, 0, 1]  # night\n",
        "            \n",
        "            # Season\n",
        "            month = dt.month\n",
        "            if month in [12, 1, 2]:\n",
        "                season = [1, 0, 0, 0]  # winter\n",
        "            elif month in [3, 4, 5]:\n",
        "                season = [0, 1, 0, 0]  # spring\n",
        "            elif month in [6, 7, 8]:\n",
        "                season = [0, 0, 1, 0]  # summer\n",
        "            else:\n",
        "                season = [0, 0, 0, 1]  # fall\n",
        "            \n",
        "            # Weekend/weekday\n",
        "            is_weekend = 1 if dt.weekday() >= 5 else 0\n",
        "            \n",
        "            # Day of week (one-hot)\n",
        "            day_of_week = [0] * 7\n",
        "            day_of_week[dt.weekday()] = 1\n",
        "            \n",
        "            # Combine all features\n",
        "            feature_row = [hour] + time_of_day + season + [is_weekend] + day_of_week\n",
        "            features.append(feature_row)\n",
        "        \n",
        "        feature_names = ['hour'] + \\\n",
        "                       ['morning', 'day', 'evening', 'night'] + \\\n",
        "                       ['winter', 'spring', 'summer', 'fall'] + \\\n",
        "                       ['is_weekend'] + \\\n",
        "                       [f'dow_{i}' for i in range(7)]\n",
        "        \n",
        "        return np.array(features), feature_names\n",
        "    \n",
        "    def create_feature_groups(self, exog_data, exog_metadata_dict):\n",
        "        \"\"\"Create feature groups based on domain knowledge\"\"\"\n",
        "        print(\"Creating feature groups based on domain knowledge...\")\n",
        "        \n",
        "        # Initialize groups\n",
        "        groups = {\n",
        "            'air_temperatures': [],\n",
        "            'water_temperatures': [],\n",
        "            'setpoints': [],\n",
        "            'control_commands': [],\n",
        "            'environmental': [],\n",
        "            'flow_pressure': [],\n",
        "            'other': []\n",
        "        }\n",
        "        \n",
        "        # Create feature names for mapping\n",
        "        feature_names = []\n",
        "        if isinstance(exog_metadata_dict, dict):\n",
        "            # If we have the metadata mapping, use it\n",
        "            name_to_idx = {name: idx for name, idx in exog_metadata_dict.items()}\n",
        "            feature_names = list(name_to_idx.keys())\n",
        "        else:\n",
        "            # Create generic names\n",
        "            feature_names = [f'feature_{i}' for i in range(exog_data.shape[1])]\n",
        "        \n",
        "        # Categorize features based on naming patterns\n",
        "        for i, feature_name in enumerate(feature_names):\n",
        "            name_lower = feature_name.lower()\n",
        "            \n",
        "            if any(keyword in name_lower for keyword in [\n",
        "                'air_temperature', 'mixed_air_temperature', \n",
        "                'supply_air_temperature', 'return_air_temperature',\n",
        "                'discharge_air_temperature', 'outside_air_temperature'\n",
        "            ]):\n",
        "                groups['air_temperatures'].append(i)\n",
        "            \n",
        "            elif any(keyword in name_lower for keyword in [\n",
        "                'water_temperature', 'supply_water_temperature',\n",
        "                'return_water_temperature', 'hot_water', 'chilled_water'\n",
        "            ]):\n",
        "                groups['water_temperatures'].append(i)\n",
        "            \n",
        "            elif any(keyword in name_lower for keyword in [\n",
        "                'setpoint', '_setpoint', 'temperature_setpoint'\n",
        "            ]):\n",
        "                groups['setpoints'].append(i)\n",
        "            \n",
        "            elif any(keyword in name_lower for keyword in [\n",
        "                'command', 'percentage_command', 'damper', 'fan_speed',\n",
        "                'valve', 'position', 'cooling', 'heating'\n",
        "            ]):\n",
        "                groups['control_commands'].append(i)\n",
        "            \n",
        "            elif any(keyword in name_lower for keyword in [\n",
        "                'outside_air', 'outdoor', 'ambient', 'humidity', \n",
        "                'dewpoint', 'wetbulb', 'pressure_sensor', 'static_pressure'\n",
        "            ]):\n",
        "                groups['environmental'].append(i)\n",
        "            \n",
        "            elif any(keyword in name_lower for keyword in [\n",
        "                'flow', 'flowrate', 'pressure', 'static', 'differential'\n",
        "            ]):\n",
        "                groups['flow_pressure'].append(i)\n",
        "            \n",
        "            else:\n",
        "                groups['other'].append(i)\n",
        "        \n",
        "        # Remove empty groups and store\n",
        "        self.feature_groups = {name: indices for name, indices in groups.items() if len(indices) > 0}\n",
        "        \n",
        "        # Print group summary\n",
        "        print(\"Feature groups created:\")\n",
        "        total_features = 0\n",
        "        for group_name, indices in self.feature_groups.items():\n",
        "            print(f\"  {group_name}: {len(indices)} features\")\n",
        "            total_features += len(indices)\n",
        "        print(f\"  Total features categorized: {total_features}/{exog_data.shape[1]}\")\n",
        "        \n",
        "        return self.feature_groups\n",
        "    \n",
        "    def fit_grouped_pca(self, exog_data, exog_metadata_dict):\n",
        "        \"\"\"Fit PCA separately for each feature group\"\"\"\n",
        "        print(f\"\\nFitting Grouped PCA (max {self.components_per_group} components per group)...\")\n",
        "        \n",
        "        # Create feature groups\n",
        "        self.create_feature_groups(exog_data, exog_metadata_dict)\n",
        "        \n",
        "        total_components = 0\n",
        "        \n",
        "        for group_name, feature_indices in self.feature_groups.items():\n",
        "            if len(feature_indices) == 0:\n",
        "                continue\n",
        "                \n",
        "            # Extract group data\n",
        "            group_data = exog_data[:, feature_indices]\n",
        "            \n",
        "            # Determine number of components (min of requested and available)\n",
        "            n_components = min(self.components_per_group, len(feature_indices), group_data.shape[0]-1)\n",
        "            \n",
        "            if n_components <= 0:\n",
        "                print(f\"  Skipping {group_name}: insufficient data\")\n",
        "                continue\n",
        "            \n",
        "            # Fit PCA for this group\n",
        "            group_pca = PCA(n_components=n_components, random_state=42)\n",
        "            group_pca.fit(group_data)\n",
        "            \n",
        "            self.group_pcas[group_name] = group_pca\n",
        "            \n",
        "            explained_variance = np.sum(group_pca.explained_variance_ratio_)\n",
        "            print(f\"  {group_name}: {len(feature_indices)} features → {n_components} components \"\n",
        "                  f\"(explained variance: {explained_variance:.3f})\")\n",
        "            \n",
        "            total_components += n_components\n",
        "        \n",
        "        print(f\"\\nGrouped PCA Summary:\")\n",
        "        print(f\"  Original features: {exog_data.shape[1]}\")\n",
        "        print(f\"  Total PCA components: {total_components}\")\n",
        "        print(f\"  Feature groups: {len(self.group_pcas)}\")\n",
        "        print(f\"  Dimensionality reduction: {exog_data.shape[1]} → {total_components}\")\n",
        "    \n",
        "    def transform_grouped_pca(self, exog_data):\n",
        "        \"\"\"Transform exogenous data using fitted grouped PCA\"\"\"\n",
        "        if not self.group_pcas:\n",
        "            raise ValueError(\"Grouped PCA not fitted yet. Call fit_grouped_pca first.\")\n",
        "        \n",
        "        transformed_groups = []\n",
        "        group_feature_names = []\n",
        "        \n",
        "        for group_name, group_pca in self.group_pcas.items():\n",
        "            # Get feature indices for this group\n",
        "            feature_indices = self.feature_groups[group_name]\n",
        "            \n",
        "            # Extract and transform group data\n",
        "            group_data = exog_data[:, feature_indices]\n",
        "            group_transformed = group_pca.transform(group_data)\n",
        "            \n",
        "            transformed_groups.append(group_transformed)\n",
        "            \n",
        "            # Create feature names for this group\n",
        "            n_components = group_transformed.shape[1]\n",
        "            group_names = [f'{group_name}_pc{i}' for i in range(n_components)]\n",
        "            group_feature_names.extend(group_names)\n",
        "        \n",
        "        # Combine all transformed groups\n",
        "        if transformed_groups:\n",
        "            combined_transformed = np.hstack(transformed_groups)\n",
        "        else:\n",
        "            combined_transformed = np.array([]).reshape(exog_data.shape[0], 0)\n",
        "        \n",
        "        return combined_transformed, group_feature_names\n",
        "    \n",
        "    def prepare_data(self, obs_data, exog_data, timestamps, temp_data=None, is_training=True):\n",
        "        \"\"\"Prepare data with interpolation, NaN handling, Grouped PCA, and feature engineering\"\"\"\n",
        "        \n",
        "        # Interpolate training data\n",
        "        if is_training:\n",
        "            obs_data = self.interpolate_zeros(obs_data) if obs_data is not None else None\n",
        "            temp_data = self.interpolate_zeros(temp_data) if temp_data is not None else None\n",
        "        \n",
        "        # Create temporal features\n",
        "        temporal_features, temporal_names = self.create_temporal_features(timestamps)\n",
        "        \n",
        "        # Apply NaN handling and Grouped PCA to exogenous features\n",
        "        if exog_data is not None:\n",
        "            # Handle NaN values first\n",
        "            exog_data_clean = self.handle_nan_values(exog_data, is_training=is_training)\n",
        "            \n",
        "            if is_training and not self.group_pcas:\n",
        "                # Fit Grouped PCA on training data\n",
        "                # We need the metadata dict for feature grouping\n",
        "                exog_metadata = exogenous_observation_data_ids if 'exogenous_observation_data_ids' in globals() else None\n",
        "                self.fit_grouped_pca(exog_data_clean, exog_metadata)\n",
        "            \n",
        "            # Transform exogenous data using Grouped PCA\n",
        "            exog_pca, exog_names = self.transform_grouped_pca(exog_data_clean)\n",
        "            \n",
        "            # Combine PCA features and temporal features\n",
        "            X = np.hstack([exog_pca, temporal_features])\n",
        "            feature_names = exog_names + temporal_names\n",
        "        else:\n",
        "            X = temporal_features\n",
        "            feature_names = temporal_names\n",
        "        \n",
        "        return X, feature_names, temp_data\n",
        "    \n",
        "    def create_hourly_bins(self, X, y, timestamps):\n",
        "        \"\"\"Create hourly bins for data\"\"\"\n",
        "        hourly_data = {}\n",
        "        \n",
        "        for i, ts in enumerate(timestamps):\n",
        "            # Handle both pandas Timestamp and Unix timestamp\n",
        "            if hasattr(ts, 'hour'):  # pandas Timestamp\n",
        "                hour = ts.hour\n",
        "            else:  # Unix timestamp\n",
        "                hour = datetime.fromtimestamp(ts).hour\n",
        "                \n",
        "            if hour not in hourly_data:\n",
        "                hourly_data[hour] = {'X': [], 'y': []}\n",
        "            hourly_data[hour]['X'].append(X[i])\n",
        "            if y is not None:\n",
        "                hourly_data[hour]['y'].append(y[i])\n",
        "        \n",
        "        # Convert to numpy arrays\n",
        "        for hour in hourly_data:\n",
        "            hourly_data[hour]['X'] = np.array(hourly_data[hour]['X'])\n",
        "            if y is not None:\n",
        "                hourly_data[hour]['y'] = np.array(hourly_data[hour]['y'])\n",
        "        \n",
        "        return hourly_data\n",
        "    \n",
        "    def optimize_hyperparameters(self, X_train, y_train, trial):\n",
        "        \"\"\"Optuna objective function for hyperparameter optimization\"\"\"\n",
        "        params = {\n",
        "            'objective': 'reg:absoluteerror',  # MAE objective\n",
        "            'tree_method': 'gpu_hist' if self.use_gpu else 'hist',\n",
        "            'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
        "            'max_depth': trial.suggest_int('max_depth', 3, 8),\n",
        "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "            'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
        "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
        "            'reg_alpha': trial.suggest_float('reg_alpha', 0.01, 10.0),\n",
        "            'reg_lambda': trial.suggest_float('reg_lambda', 0.01, 10.0),\n",
        "            'random_state': 42,\n",
        "            'n_jobs': 1\n",
        "        }\n",
        "        \n",
        "        base_model = xgb.XGBRegressor(**params)\n",
        "        model = MultiOutputRegressor(base_model, n_jobs=1)\n",
        "        \n",
        "        # Simple train/validation split for optimization\n",
        "        split_idx = int(0.8 * len(X_train))\n",
        "        X_tr, X_val = X_train[:split_idx], X_train[split_idx:]\n",
        "        y_tr, y_val = y_train[:split_idx], y_train[split_idx:]\n",
        "        \n",
        "        model.fit(X_tr, y_tr)\n",
        "        y_pred = model.predict(X_val)\n",
        "        \n",
        "        return mean_absolute_error(y_val, y_pred)\n",
        "    \n",
        "    def train_hourly_models(self, X_train, y_train, timestamps_train, n_trials=5):\n",
        "        \"\"\"Train 24 hourly XGBoost models with hyperparameter optimization\"\"\"\n",
        "        \n",
        "        # Create hourly bins\n",
        "        hourly_train_data = self.create_hourly_bins(X_train, y_train, timestamps_train)\n",
        "        \n",
        "        print(f\"Training {len(hourly_train_data)} hourly models...\")\n",
        "        \n",
        "        for hour in range(24):\n",
        "            if hour not in hourly_train_data:\n",
        "                print(f\"No data for hour {hour}, skipping...\")\n",
        "                continue\n",
        "                \n",
        "            print(f\"Training model for hour {hour}...\")\n",
        "            \n",
        "            X_hour = hourly_train_data[hour]['X']\n",
        "            y_hour = hourly_train_data[hour]['y']\n",
        "            \n",
        "            if len(X_hour) < 10:\n",
        "                print(f\"Too few samples for hour {hour} ({len(X_hour)}), skipping...\")\n",
        "                continue\n",
        "            \n",
        "            # Scale features\n",
        "            scaler = StandardScaler()\n",
        "            X_hour_scaled = scaler.fit_transform(X_hour)\n",
        "            self.scalers[hour] = scaler\n",
        "            \n",
        "            # Optimize hyperparameters\n",
        "            study = optuna.create_study(direction='minimize', study_name=f'hour_{hour}')\n",
        "            \n",
        "            def objective(trial):\n",
        "                return self.optimize_hyperparameters(X_hour_scaled, y_hour, trial)\n",
        "            \n",
        "            study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
        "            \n",
        "            # Train final model with best parameters\n",
        "            best_params = study.best_params\n",
        "            best_params.update({\n",
        "                'objective': 'reg:absoluteerror',\n",
        "                'tree_method': 'gpu_hist' if self.use_gpu else 'hist',\n",
        "                'random_state': 42,\n",
        "                'n_jobs': 1\n",
        "            })\n",
        "            \n",
        "            base_model = xgb.XGBRegressor(**best_params)\n",
        "            model = MultiOutputRegressor(base_model, n_jobs=1)\n",
        "            model.fit(X_hour_scaled, y_hour)\n",
        "            \n",
        "            self.models[hour] = model\n",
        "            \n",
        "            print(f\"Hour {hour} - Best MAE: {study.best_value:.4f}\")\n",
        "        \n",
        "        print(f\"Training completed. {len(self.models)} models trained.\")\n",
        "    \n",
        "    def predict(self, X_test, timestamps_test):\n",
        "        \"\"\"Make predictions using hourly models\"\"\"\n",
        "        first_model = self.models[list(self.models.keys())[0]]\n",
        "        n_outputs = len(first_model.estimators_)\n",
        "        \n",
        "        predictions = np.zeros((len(X_test), n_outputs))\n",
        "        \n",
        "        # Create hourly bins for test data\n",
        "        hourly_test_data = self.create_hourly_bins(X_test, None, timestamps_test)\n",
        "        \n",
        "        for hour in hourly_test_data:\n",
        "            if hour not in self.models:\n",
        "                available_hours = list(self.models.keys())\n",
        "                hour_to_use = min(available_hours, key=lambda x: abs(x - hour))\n",
        "                print(f\"Using model for hour {hour_to_use} instead of hour {hour}\")\n",
        "            else:\n",
        "                hour_to_use = hour\n",
        "            \n",
        "            X_hour = hourly_test_data[hour]['X']\n",
        "            X_hour_scaled = self.scalers[hour_to_use].transform(X_hour)\n",
        "            \n",
        "            hour_predictions = self.models[hour_to_use].predict(X_hour_scaled)\n",
        "            \n",
        "            # Map predictions back to original indices\n",
        "            hour_indices = []\n",
        "            for i, ts in enumerate(timestamps_test):\n",
        "                if hasattr(ts, 'hour'):\n",
        "                    ts_hour = ts.hour\n",
        "                else:\n",
        "                    ts_hour = datetime.fromtimestamp(ts).hour\n",
        "                    \n",
        "                if ts_hour == hour:\n",
        "                    hour_indices.append(i)\n",
        "            \n",
        "            for i, idx in enumerate(hour_indices):\n",
        "                predictions[idx] = hour_predictions[i]\n",
        "        \n",
        "        return predictions\n",
        "    \n",
        "    def evaluate_predictions(self, y_true, y_pred, timestamps_test):\n",
        "        \"\"\"Evaluate predictions for different time periods\"\"\"\n",
        "        results = {}\n",
        "        \n",
        "        # Convert timestamps to datetime for easier handling\n",
        "        dates = []\n",
        "        for ts in timestamps_test:\n",
        "            if hasattr(ts, 'to_pydatetime'):\n",
        "                dates.append(ts.to_pydatetime())\n",
        "            elif hasattr(ts, 'hour'):\n",
        "                dates.append(ts)\n",
        "            else:\n",
        "                dates.append(datetime.fromtimestamp(ts))\n",
        "        \n",
        "        start_date = min(dates)\n",
        "        \n",
        "        # Define evaluation periods\n",
        "        periods = {\n",
        "            'first_week': timedelta(days=7),\n",
        "            'first_2_weeks': timedelta(days=14),\n",
        "            'first_month': timedelta(days=30),\n",
        "            'first_3_months': timedelta(days=90),\n",
        "            'entire_period': timedelta(days=365)\n",
        "        }\n",
        "        \n",
        "        for period_name, period_length in periods.items():\n",
        "            end_date = start_date + period_length\n",
        "            \n",
        "            period_indices = [i for i, date in enumerate(dates) if date <= end_date]\n",
        "            \n",
        "            if period_indices:\n",
        "                y_true_period = y_true[period_indices]\n",
        "                y_pred_period = y_pred[period_indices]\n",
        "                \n",
        "                mae = mean_absolute_error(y_true_period, y_pred_period)\n",
        "                results[period_name] = mae\n",
        "                print(f\"{period_name}: MAE = {mae:.4f}\")\n",
        "        \n",
        "        return results\n",
        "\n",
        "# Main execution function\n",
        "def run_smart_buildings_model():\n",
        "    \"\"\"Main function to run the complete model\"\"\"\n",
        "    \n",
        "    print(\"Initializing Smart Buildings Predictor with Grouped PCA...\")\n",
        "    predictor = SmartBuildingsPredictor(use_gpu=True, components_per_group=15)\n",
        "    \n",
        "    # Prepare training data\n",
        "    print(\"Preparing training data...\")\n",
        "    \n",
        "    # Extract training temperature data (target) from cleaned preprocessed data\n",
        "    train_temp_indices = [v for k, v in metadata['observation_ids'].items() \n",
        "                         if \"zone_air_temperature_sensor\" in k]\n",
        "    train_temp_data = train_obs_matrix_clean[:, train_temp_indices]\n",
        "    \n",
        "    # Extract training exogenous data from cleaned preprocessed data\n",
        "    train_exog_indices = [v for k, v in metadata['observation_ids'].items() \n",
        "                         if \"zone_air_temperature_sensor\" not in k]\n",
        "    train_exog_data = train_obs_matrix_clean[:, train_exog_indices]\n",
        "    \n",
        "    # Prepare training features and targets using cleaned timestamps\n",
        "    X_train, feature_names, y_train = predictor.prepare_data(\n",
        "        None, train_exog_data, timestamps_train_clean, \n",
        "        train_temp_data, is_training=True\n",
        "    )\n",
        "    \n",
        "    predictor.feature_columns = feature_names\n",
        "    \n",
        "    print(f\"Training data shape: X={X_train.shape}, y={y_train.shape}\")\n",
        "    print(f\"Feature names: {len(feature_names)} features\")\n",
        "    \n",
        "    # Train models using cleaned timestamps with 5 trials\n",
        "    predictor.train_hourly_models(X_train, y_train, timestamps_train_clean, n_trials=5)\n",
        "    \n",
        "    # Prepare test data using cleaned validation data\n",
        "    print(\"Preparing test data...\")\n",
        "    X_test, _, _ = predictor.prepare_data(\n",
        "        None, exogenous_observation_data, timestamps_val_clean, \n",
        "        None, is_training=False\n",
        "    )\n",
        "    \n",
        "    print(f\"Test data shape: {X_test.shape}\")\n",
        "    \n",
        "    # Make predictions using cleaned validation timestamps\n",
        "    print(\"Making predictions...\")\n",
        "    predictions = predictor.predict(X_test, timestamps_val_clean)\n",
        "    \n",
        "    print(f\"Predictions shape: {predictions.shape}\")\n",
        "    print(f\"True values shape: {temp_data.shape}\")\n",
        "    \n",
        "    # Evaluate results using cleaned validation timestamps\n",
        "    print(\"\\nEvaluation Results:\")\n",
        "    print(\"=\" * 50)\n",
        "    results = predictor.evaluate_predictions(\n",
        "        temp_data, predictions, timestamps_val_clean\n",
        "    )\n",
        "    \n",
        "    return predictor, predictions, results\n",
        "\n",
        "# Run the model\n",
        "if __name__ == \"__main__\":\n",
        "    predictor, predictions, results = run_smart_buildings_model()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
